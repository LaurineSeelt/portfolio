[["index.html", "Portfolio Laurine Seelt 1 Introduction", " Portfolio Laurine Seelt Laurine Seelt 2022-05-17 1 Introduction This is the introduction to the portfolio of Laurine Seelt. She worked really hard on this. Please be kind to them. "],["investigating-a-c.-elegans-plate-experiment.html", "2 Investigating a C. Elegans plate experiment", " 2 Investigating a C. Elegans plate experiment This was the first assignment for our portfolio. We had to look at the data of a C. Elegans plate experiment, plot some of the data and normalise the data for the negative control to get a clearer graph. First I took a look at the data and read it in RStudio. # View(here(&quot;Data/Data_raw/CE.LIQ.FLOW.062_Tidydata.xlsx&quot;)) Tidydata &lt;- read_excel(here(&quot;Data/Data_raw/CE.LIQ.FLOW.062_Tidydata.xlsx&quot;)) Tidydata &lt;- as.data.frame(Tidydata) Next, I looked at the columns RawData, compName and compConcentration to see what type they were. typeof(Tidydata$RawData) ## [1] &quot;double&quot; typeof(Tidydata$compName) ## [1] &quot;character&quot; typeof(Tidydata$compConcentration) ## [1] &quot;character&quot; RawData is double, dat is te begrijpen, het zijn getallen. CompName is een character, dat is ook te begrijpen. In die kolom staan de namen van de stofjes die zijn gebruikt. CompConcentration is een character, wat wel apart is. In die kolom staan de concentraties van de gebruikte stofjes, dus je zou verwachten dat dit een numerieke kolom zou zijn. Then I plotted the data in a scatter plot. Tidydata %&gt;% ggplot(aes(x = compConcentration, y = RawData, colour = compName, shape = expType))+ geom_point() De X-as is niet heel mooi of leesbaar. Volgens mij worden de getallen geordend op basis van met welk getal ze beginnen, niet de daadwerkelijke grootte. Dus bijvoorbeeld 4,05x10-5 staat verder naar rechts dan 0,1 omdat 4,05x10-5 dus met een 4 begint. CompConcentration is een character kolom, dus daarom gebeurt dit. Er wordt niet ‘rekening gehouden’ met de machten. Om de X-as leesbaarder te maken, heb ik de kolom compConcentration naar numeric veranderd en heb ik de Log10 van de concentratie geplot. Ook heb ik geom_jitter gebruikt om wat afstand te creëren tussen de datapunten, zodat de grafiek nog wat duidelijker wordt. Tidydata$compConcentration &lt;- as.numeric(Tidydata$compConcentration) Tidydata %&gt;% ggplot(aes(x = (log10(compConcentration + 0.001)), y = RawData, colour = compName, shape = expType)) + geom_point() + geom_jitter(position = position_jitter(0.2)) De positieve controle waren C. Elegans die met Ethanol zijn behandeld. De negatieve controle waren C. Elegans die met S-medium zijn behandeld. Om te analyseren of verschillende concentraties effect hebben op de hoeveelheid nakomelingen, zou ik aparte tabellen maken per stof (en per concentratie?). Dan kan je het gemiddelde en de standaard deviatie per stof en per concentratie berekenen. Ook kan je dan per stof een ANOVA test uitvoeren, om te kijken of het effect significant is. Dus 1. Aparte tabellen maken met de metingen per stof. 2. Het gemiddelde en de standaardeviatie berekenen voor elke concentratie van elke stof. 3. Een ANOVA test uitvoeren voor elke stof om te kijken of er dus inderdaad significante verschillen zijn in effect tussen de concentraties. Om te analyseren of de verschillende stoffen een andere curve/IC50 hebben, moet je per stof kijken naar het effect op de hoeveelheid nakomelingen. Daar kan je een grafiek van maken, met op de x-as de concentratie van de stof en op de y-as de hoeveelheid nakomelingen. Deze grafieken zou je bijvoorbeeld in hetzelfde assenstelsel kunnen plotten, om ze met elkaar te kunnen vergelijken. Als laatste heb ik de data genormaliseerd voor de negatieve controle en dat weer geplot in een scatter plot. Tidydata$compConcentration &lt;- as.numeric(Tidydata$compConcentration) Tibble_mean &lt;- Tidydata %&gt;% group_by(compName, compConcentration) %&gt;% summarize(by = &quot;compName&quot;, mean = mean(RawData, na.rm = TRUE)) # Het gemiddelde van de negatieve controle, S-medium, is 85,9. Dat is dus de waarde waar de andere gemiddelden voor genormaliseerd moeten worden. Tibble_mean &lt;- Tibble_mean %&gt;% mutate(mean_norm = mean / 85.9) Tibble_mean %&gt;% ggplot(aes(x = (log10(compConcentration + 0.001)), y = mean_norm, colour = compName, shape = compName)) + geom_point() + geom_line() + labs(title = &quot;The effect of different compounds on the amount of offspring&quot;, x = &quot;Compound concentration (log10 + 0.001)&quot;, y = &quot;Mean offspring, normalised for S-medium&quot;) Dit heb ik gedaan omdat je dan duidelijker het effect kan zien van de verschillende stoffen en verschillende concentraties. De grafiek is veel overzichtelijker op deze manier. Ook kan je duidelijk per stof en per concentratie het verschil zien met de negatieve controle. "],["reading-two-different-studies-and-recreating-some-of-the-code.html", "3 Reading two different studies and recreating some of the code 3.1 Part 1 3.2 Part 2", " 3 Reading two different studies and recreating some of the code This was the second assignment for our portfolio. We had to look up two different articles, answer some questions about it and recreate some of the code from one of the articles. 3.1 Part 1 Link to the study: https://pubmed.ncbi.nlm.nih.gov/29324233/ Category Score Study_purpose TRUE Data_availability_statement TRUE Data_location TRUE Study_location TRUE Author_review 7 Ethics_statement FALSE Funding_statement TRUE Code_availability TRUE In this study, researchers investigated the heterologous effects of Bacillus Calmette-Guérin (BCG) vaccination against other, non-related virus infections. It has been known for some time that BCG vaccination has positive heterologous effects against other virusses, but the exact immunological basis for this effect has never been examined in depth. The researchers in this study examined the genome-wide histone modifications that take place as a result of BCG vaccination, and also examined the functional changes in monocytes that take place after BCG vaccination. The effect of BCG vaccination on viral, serological and immunological parameters after administration of the Yellow Fever Vaccine was also examined. The method used for this study was ChIP-sequencing, to look at genome-wide changes in the distribution of H3K27ac. H3K27ac is a marker of active promoters and enhancers. This was done before BCG vaccination and one month after BCG vaccination. Correlation plots showed a clear distinction between the two kinds of samples. Most changes between the two kinds of samples were related to G-protein coupled receptors and protein kinases, which shows that BCG vaccination has a substantial effect on remodeling signal transduction molecules. The researchers also showed that the cytokine response to unrelated pathogens was enhanced one month after BCG vaccination. The heterologous T-cell response was also moderately enhanced after BCG vaccination. Next, this study looked at the difference in immune response to the Yellow Fever Vaccine between people who had had the BCG vaccination, and people who hadn’t. People who had had the vaccine had a significantly lower viremia compared to people who had had the placebo vaccine. It was seen that mainly increased IL1-B and IL-10 production predicted a lower viremia in subjects who had had the BCG vaccine. 3.2 Part 2 Link to the study: https://osf.io/aqycd/ The code is very readable, 4. Recreating figure 1A library(tidyverse) library(ggplot2) library(here) library(viridis) ################################################################################################## ##### Descriptives; d &lt;- as_tibble(read.csv2(here(&quot;Data/Data_LittSurvey_Box1.csv&quot;))) d &lt;- d %&gt;% mutate(Hypo=ifelse(Clearly.stated.hypothesis&gt;1, 1, 0)) %&gt;% mutate(Experiment=ifelse(Study.design==&quot;Experimental&quot;, 1,0)) %&gt;% mutate(YearLaps=abs(Year-2016)) %&gt;% mutate(Scope2=ifelse(Scope==&quot;Methods&quot;, &quot;Methods&quot;, &quot;Biodiversity response&quot;)) %&gt;% mutate(Hypothesis2=Clearly.stated.hypothesis) %&gt;% mutate(Hypothesis2=ifelse(Hypothesis2==0, &quot;No&quot;, ifelse(Hypothesis2==1, &quot;Partly&quot;, ifelse(Hypothesis2==2, &quot;Implied&quot;, &quot;Clearly stated&quot;)))) ############################################### ##### cleary stated hypotheis; ## Plotting results; ## Clearly stated hypothesis; ## Figure 1a Hypothesis_prop &lt;- d %&gt;% group_by(Hypothesis2, Scope2) %&gt;% count(Clearly.stated.hypothesis) %&gt;% mutate(prop=prop.table(n)) %&gt;% mutate(Hypothesis3= factor(Hypothesis2, levels=c(&quot;No&quot;, &quot;Implied&quot;, &quot;Partly&quot;, &quot;Clearly stated&quot;))) %&gt;% mutate(Scope3= factor(Scope2, levels=c(&quot;Methods&quot;, &quot;Biodiversity response&quot;))) Hypothesis_prop2 &lt;- d %&gt;% filter(Scope==&quot;Ecological processes&quot;) %&gt;% count(Clearly.stated.hypothesis) %&gt;% mutate(prop=prop.table(n)) p &lt;- ggplot(data=Hypothesis_prop, aes(x=Hypothesis3, y=n, fill=Scope3)) + geom_bar(stat=&quot;identity&quot;, width=0.7, ) + theme_minimal() + theme(text = element_text(size=15), legend.position = &quot;bottom&quot;, legend.title = element_blank(), axis.text.y = element_text(size=17)) + ylim(0, 100)+ labs(x=&quot;&quot;, y=&quot;Number of articles&quot;, title=&quot;&quot;) + scale_fill_brewer(palette=&quot;Blues&quot;) p+coord_flip() In the field of applied ecological research, the lines between exploratory research and confirmatory research are becoming more and more blurred. A lot of researchers in the field of applied ecology do not follow the strong inference paradigm. This means that a lot of researchers in this field often don’t devise an alternative hypothesis when they’re conducting their research. What’s more, they often don’t even devise a hypothesis before conducting their research. This is dangerous, and could, for example, lead to more confirmation bias in this field. The researchers of this paper looked at 159 papers from conservation/applied ecology/wildife journals. They scored all the papers on certain criteria, to see how the experiments were conducted. This figure displays the amount of papers that had either a clearly stated hypothesis or not, divided by what the research focussed on: methods or biodiversity response. Reproducibility of the code: 5. It was very easy, I barely needed to change anything before I got the pretty graph :) "],["cleaning-up-according-to-the-guerrilla-analytics-framework.html", "4 Cleaning up according to the Guerrilla analytics framework", " 4 Cleaning up according to the Guerrilla analytics framework This was the third assignment for our portfolio. We had to apply the Guerrilla analytics framework to our DAUR2 folder. fs::dir_tree(path = here(&quot;Daur2&quot;), type = &quot;directory&quot;) ## C:/Users/lautj/Documents/DSFB2/portfolio/Daur2 ## ├── Code ## ├── Data ## │ ├── Metagenomics ## │ │ ├── Data_raw ## │ │ └── Supporting ## │ └── RNA_seq ## │ └── Data_raw ## ├── R ## └── Rmd "],["cv.html", "5 CV 5.1 Persoonlijke informatie 5.2 Opleiding 5.3 Ervaring/skills 5.4 Talen", " 5 CV This was the fourth assignment for our portfolio. We had to put our CV in a markdown. 5.1 Persoonlijke informatie Naam: Laurine Seelt Emailadres: - Telefoonnummer: - Adres: - Postcode: - Woonplaats: - 5.2 Opleiding 2019 - heden Bachelor Life Sciences, Hogeschool Utrecht 2012 - 2018 VWO, Erfgooiers College te Huizen 5.3 Ervaring/skills (q)PCR, Western Blot, ELISA, MALDI-TOF, Bash, R, SQL, 5.4 Talen Nederlands, moedertaal. Engels, vloeiend. "],["free-space.html", "6 Free space 6.1 Course: Introduction to the statistical analysis of microbiome data in R 6.2 Course: Microbiota analysis in R", " 6 Free space This was the fifth assignment for our portfolio. We had/have to fill 32 hours learning something new that will be useful for our internship next year and possibly our job. Uitzoeken welke automatiseringen er op microbiologische labs worden gebruikt. Metagenomics? https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-020-03933-4 (megaR package) http://web.evolbio.mpg.de/~wang/Site/R_tutorial_files/16S%20Metagenomic%20Analysis%20Tutorial.pdf (random tutorial) https://www.mcs.anl.gov/~braithwaite/matR/docs-and-pubs/matR-user-manual.pdf (matR package) https://rpubs.com/jrandall7/EICC16s (phyloseq) https://cran.r-project.org/web/packages/microbial/microbial.pdf (microbial package) https://bioconductor.org/help/course-materials/2017/BioC2017/Day1/Workshops/Microbiome/MicrobiomeWorkflowII.html (aritkel over microbioom analyse workflow) https://www.nicholas-ollberding.com/post/introduction-to-the-statistical-analysis-of-microbiome-data-in-r/ (soort course over de analyse van microbioom data) https://rstudio-pubs-static.s3.amazonaws.com/268156_d3ea37937f4f4469839ab6fa2c483842.html (ook een course over de analyse van microbiota data) https://grunwaldlab.github.io/analysis_of_microbiome_community_data_in_r/04--manipulating.html (nog een course) - Python? 6.1 Course: Introduction to the statistical analysis of microbiome data in R Link to the course: https://www.nicholas-ollberding.com/post/introduction-to-the-statistical-analysis-of-microbiome-data-in-r/ In this course, we examined the differences in microbiota between patients with and without chronic fatigue syndrome. The aspects that were looked at were: Taxonomic relative abundance Hierarchal clustering Alpha-diversity (microbiome diversity in just one sample) Beta-divesity (microbiome diversity in two or more samples) Diffrential abundance testing Predicting class labels .cran_packages &lt;- c(&quot;tidyverse&quot;, &quot;cowplot&quot;, &quot;picante&quot;, &quot;vegan&quot;, &quot;HMP&quot;, &quot;dendextend&quot;, &quot;rms&quot;, &quot;devtools&quot;) .bioc_packages &lt;- c(&quot;phyloseq&quot;, &quot;DESeq2&quot;, &quot;microbiome&quot;, &quot;metagenomeSeq&quot;, &quot;ALDEx2&quot;) .inst &lt;- .cran_packages %in% installed.packages() if(any(!.inst)) { install.packages(.cran_packages[!.inst]) } if (!requireNamespace(&quot;BiocManager&quot;, quietly = TRUE)) install.packages(&quot;BiocManager&quot;) BiocManager::install(.bioc_packages, version = &quot;3.15&quot;) #Changed 3.9 to 3.15 devtools::install_github(&quot;adw96/breakaway&quot;) devtools::install_github(repo = &quot;malucalle/selbal&quot;) #changed UVic-omics to malucalle library(tidyverse) library(phyloseq) library(DESeq2) library(microbiome) library(vegan) library(picante) library(ALDEx2) library(metagenomeSeq) library(HMP) library(dendextend) library(selbal) library(rms) library(breakaway) # Reading in the data ps &lt;- readRDS(&quot;Data/Data_raw/ps_giloteaux_2016.rds&quot;) # Sorting the samples on total read count sort(phyloseq::sample_sums(ps)) # Removing (samples with?) less than 5000 reads (ps &lt;- phyloseq::subset_samples(ps, phyloseq::sample_sums(ps) &gt; 5000)) # Removing the OTU&#39;s that were only present in the removed samples (ps &lt;- phyloseq::prune_taxa(phyloseq::taxa_sums(ps) &gt; 0, ps)) # Assigning a new metadata field phyloseq::sample_data(ps)$Status &lt;- ifelse(phyloseq::sample_data(ps)$Subject == &quot;Patient&quot;, &quot;Chronic Fatique&quot;, &quot;Control&quot;) phyloseq::sample_data(ps)$Status &lt;- factor(phyloseq::sample_data(ps)$Status, levels = c(&quot;Control&quot;, &quot;Chronic Fatique&quot;)) ps %&gt;% sample_data %&gt;% dplyr::count(Status) # Counting all the phyla in the dataset table(phyloseq::tax_table(ps)[, &quot;Phylum&quot;]) # Convert the samples to relative abundances ps_rel_abund = phyloseq::transform_sample_counts(ps, function(x){x / sum(x)}) phyloseq::otu_table(ps)[1:5, 1:5] # Before we converted it to relative abundances phyloseq::otu_table(ps_rel_abund)[1:5, 1:5] # After we calculated the relative abundances # Plotting the relative abundances, devided by the two groups phyloseq::plot_bar(ps_rel_abund, fill = &quot;Phylum&quot;)+ geom_bar(aes(color = Phylum, fill = Phylum), stat = &quot;identity&quot;, position = &quot;stack&quot;)+ labs(x = &quot;&quot;, y = &quot;Relative Abundance\\n&quot;)+ facet_wrap(~ Status, scales = &quot;free&quot;)+ theme(panel.background = element_blank(), axis.text.x = element_blank(), axis.ticks.x = element_blank()) # Sorting the taxa by their relative abundance sort(ps_rel_abund@tax_table[[&quot;Phylum&quot;]], decreasing = TRUE) %&gt;% phyloseq::plot_bar(fill = &quot;Phylum&quot;)+ geom_bar(aes(color = Phylum, fill = Phylum), stat = &quot;identity&quot;, position = &quot;stack&quot;)+ labs(x = &quot;&quot;, y = &quot;Relative Abundance\\n&quot;)+ facet_wrap(~ Status, scales = &quot;free&quot;)+ theme(panel.background = element_blank(), axis.text.x = element_blank(), axis.ticks.x = element_blank()) # Grouping the taxa according to phylum and renaming the groups ps_phylum &lt;- phyloseq::tax_glom(ps, &quot;Phylum&quot;) phyloseq::taxa_names(ps_phylum) &lt;- phyloseq::tax_table(ps_phylum)[, &quot;Phylum&quot;] phyloseq::otu_table(ps_phylum)[1:5, 1:5] # Melting the data and making the boxplots phyloseq::psmelt(ps_phylum) %&gt;% ggplot(data = ., aes(x = Status, y = Abundance))+ geom_boxplot(outlier.shape = NA)+ geom_jitter(aes(colour = OTU), height = 0, width = 0.2)+ labs(x = &quot;&quot;, y = &quot;Abundance\\n&quot;)+ facet_wrap(~ OTU, scales = &quot;free&quot;) # Making two subsets controls &lt;- phyloseq::subset_samples(ps_phylum, Status == &quot;Control&quot;) cf &lt;- phyloseq::subset_samples(ps_phylum, Status = &quot;Chronic Fatigue&quot;) # Looking at the OTU tables control_otu &lt;- data.frame(phyloseq::otu_table(controls)) cf_otu &lt;- data.frame(phyloseq::otu_table(cf)) # Grouping the rare phyla to improve testing control_otu &lt;- control_otu %&gt;% t(.) %&gt;% as.data.frame(.) %&gt;% mutate(Other = Cyanobacteria + Euryarchaeota + Tenericutes + Verrucomicrobia + Fusobacteria) %&gt;% dplyr::select(-Cyanobacteria, -Euryarchaeota, -Tenericutes, -Verrucomicrobia, -Fusobacteria) cf_otu &lt;- cf_otu %&gt;% t(.) %&gt;% as.data.frame(.) %&gt;% mutate(Other = Cyanobacteria + Euryarchaeota + Tenericutes + Verrucomicrobia + Fusobacteria) %&gt;% dplyr::select(-Cyanobacteria, -Euryarchaeota, -Tenericutes, -Verrucomicrobia, -Fusobacteria) # Performing the HMP test group_data &lt;- list(control_otu, cf_otu) (xdc &lt;- HMP::Xdc.sevsample(group_data)) 1 - pchisq(0.2769004, 5) # Looking at the Chi-Squared distribution Since the P-value of the HMP test is nearly 1, we cannot reject the null hypothesis that there is no statistical significant distribution of phyla between the two groups. Looking at the hierarchical clustering in the samples # Extracting the OTU table ps_rel_otu &lt;- data.frame(phyloseq::otu_table(ps_rel_abund)) ps_rel_otu &lt;- t(ps_rel_otu) # Computing the Bray-Curtis dissimilarity bc_dist &lt;- vegan::vegdist(ps_rel_otu, method = &quot;bray&quot;) # Generating a matrix with the dissimilarities as.matrix(bc_dist)[1:5, 1:5] # Saving it as a dendrogram ward &lt;- as.dendrogram(hclust(bc_dist, method = &quot;ward.D2&quot;)) # Adding color coding meta &lt;- data.frame(phyloseq::sample_data(ps_rel_abund)) colorCode &lt;- c(Control = &quot;red&quot;, `Chronic Fatigue` = &quot;blue&quot;) labels_colors(ward) &lt;- colorCode[meta$Status][order.dendrogram(ward)] # Plotting the dendrogram plot(ward) plot_heatmap(cf) plot_heatmap(controls) Looking at the alpha diversity Alpha diversity looks at the diversity within a sample and how the observed OTU’s are distributed. # Plotting the observed richness ggplot(data = data.frame(&quot;total_reads&quot; = phyloseq::sample_sums(ps), &quot;observed&quot; = phyloseq::estimate_richness(ps, measures = &quot;Observed&quot;)[, 1]), aes(x = total_reads, y = observed)) + geom_point() + geom_smooth(method=&quot;lm&quot;, se = FALSE) + labs(x = &quot;\\nTotal Reads&quot;, y = &quot;Observed richness\\n&quot;) Now we’re going to subsample the reads, plot them and test for group differences # Subsample reads (ps_rare &lt;- phyloseq::rarefy_even_depth(ps, rngseed = 123, replace = FALSE)) head(phyloseq::sample_sums(ps_rare)) # Making a dataframe with the adiv measures, another package to analyse and measure biodiversity adiv &lt;- data.frame(&quot;Observed&quot; = phyloseq::estimate_richness(ps_rare, measures = &quot;Observed&quot;), &quot;Shannon&quot; = phyloseq::estimate_richness(ps_rare, measures = &quot;Shannon&quot;), &quot;PD&quot; = picante::pd(samp = data.frame(t(data.frame(phyloseq::otu_table(ps_rare)))), include.root = FALSE, tree=phyloseq::phy_tree(ps_rare))[, 1], &quot;Status&quot; = phyloseq::sample_data(ps_rare)$Status) # Zelf &quot;include.root = FALSE&quot; toegevoegd, anders kreeg ik steeds een error head(adiv) # Plotting the adiv measures adiv %&gt;% gather(key = metric, value = value, c(&quot;Observed&quot;, &quot;Shannon&quot;, &quot;PD&quot;)) %&gt;% mutate(metric = factor(metric, levels = c(&quot;Observed&quot;, &quot;Shannon&quot;, &quot;PD&quot;))) %&gt;% ggplot(aes(x = Status, y = value)) + geom_boxplot(outlier.color = NA) + geom_jitter(aes(color = Status), height = 0, width = 0.2) + labs(x = &quot;&quot;, y = &quot;&quot;) + facet_wrap(~metric, scales = &quot;free&quot;) + theme(legend.position = &quot;none&quot;) # Summarising the data adiv %&gt;% group_by(Status) %&gt;% dplyr::summarise(median_observed = median(Observed), median_shannon = median(Shannon), median_pd = median(PD)) # Performing the Wilcoxon tests for the three estimates wilcox.test(Observed ~ Status, data = adiv, exact = FALSE, conf.int = TRUE) wilcox.test(Shannon ~ Status, data = adiv, conf.int = TRUE) wilcox.test(PD ~ Status, data = adiv, conf.int = TRUE) Looking at the beta diversity Beta diversity looks at the diversity between samples and how it’s similar or dissimilar. # Transforming the Total Read Counts according to the Centered Log Ratio method (ps_clr &lt;- microbiome::transform(ps, &quot;clr&quot;)) phyloseq::otu_table(ps)[1:5, 1:5] # Old OTU table phyloseq::otu_table(ps_clr)[1:5, 1:5] # New OTU table # The value are now the dominance for each taxa relative to the geometric mean of all taxa on the logarithmic scale 6.2 Course: Microbiota analysis in R Link to the course: https://rstudio-pubs-static.s3.amazonaws.com/268156_d3ea37937f4f4469839ab6fa2c483842.html In this course, we will be looking at the fecal bacterial microbiota of 8 calves at ages 2 weeks, 8 weeks and 1 year old and correlating them with variables such as weight gain, expressed as Average Daily Gain in Kilograms(ADGKG), and gastrointestinal short chain fatty acids, SCFA. # install.packages(&quot;ape&quot;) library(ape) library(tidyverse) library(dplyr) library(ggplot2) library(gplots) library(lme4) library(phangorn) library(plotly) library(tidyr) library(here) library(vegan) # install.packages(&quot;VennDiagram&quot;) library(VennDiagram) # Installed Java from: https://www.java.com/en/download/manual.jsp # Installed Java JDk from: https://www.oracle.com/java/technologies/downloads/#jdk18-windows # install.packages(&quot;rJava&quot;) library(rJava) # install.packages(&quot;venneuler&quot;) # library(venneuler) # R kapt er steeds mee als ik deze wil laden # if (!require(&quot;BiocManager&quot;, quietly = TRUE)) # install.packages(&quot;BiocManager&quot;) # BiocManager::install(version = &quot;3.15&quot;) # Instead of source(&quot;https://bioconductor.org/biocLite.R&quot;) # BiocManager::install(&quot;phyloseq&quot;) # Instead of biocLite(&quot;phyloseq&quot;) ? library(phyloseq) # Downloaded the data from: https://github.com/kdillmcfarland/workshops_UW_Madison/tree/master/Microbiota_analysis_R/Data OTU = read.table(&quot;Data/example.final.an.unique_list.0.03.norm.shared.txt&quot;, header = TRUE, sep = &quot;\\t&quot;) tax = read.table(&quot;Data/example.final.an.unique_list.0.03.cons.taxonomy.txt&quot;, header = TRUE, sep = &quot;\\t&quot;) meta = read.table(&quot;Data/example.metadata.txt&quot;, header = TRUE, row.names = 1, sep = &quot;\\t&quot;) SCFA = read.table(&quot;Data/example.SCFA.txt&quot;, header = TRUE, row.names = 1, sep = &quot;\\t&quot;) # Setting the &quot;Group&quot; column as row names in the OTU dataset row.names(OTU) = OTU$Group # Removing the columns that are not OTU counts OTU.clean = OTU[,-which(names(OTU) %in% c(&quot;label&quot;, &quot;numOtus&quot;, &quot;Group&quot;))] # Setting the &quot;OTU&quot; column as row names in the taxonomy table row.names(tax) = tax$OTU # Removing the OTU&#39;s that aren&#39;t present in the OTU.clean dataset tax.clean = tax[row.names(tax) %in% colnames(OTU.clean),] # Separating the taxonomy table so each level has its own column tax.clean = separate(tax.clean, Taxonomy, into = c(&quot;Domain&quot;, &quot;Phylum&quot;, &quot;Class&quot;, &quot;Order&quot;, &quot;Family&quot;, &quot;Genus&quot;, &quot;Species&quot;, &quot;Strain&quot;), sep = &quot;;&quot;) # Removing the &quot;Size&quot;, &quot;Strain&quot; and &quot;OTU&quot; columns because these are now row names tax.clean = tax.clean[,-which(names(tax.clean) %in% c(&quot;Size&quot;, &quot;Strain&quot;, &quot;OTU&quot;))] # Making sure the three datasets have samples in the same order OTU.clean = OTU.clean[order(row.names(OTU.clean)),] meta = meta[order(row.names(meta)),] SCFA = SCFA[order(row.names(SCFA)),] # set.seed to make the analysis reproducible set.seed(8765) Looking at the alpha diversity Alpha diversity is the diversity within a sample. It looks at richness, which is the amount of OTU’s in each sample, and at evenness, which is how evenly the different OTU’s are distributed within the sample. # Creating a 2x2 plot environment so we can see all 4 metrics at once par(mfrow = c(2,2)) # Plotting the four metrics hist(meta$shannon, main = &quot;Shannon diversity&quot;, xlab = &quot;&quot;, breaks = 10) hist(meta$simpson, main = &quot;Simpson diversity&quot;, xlab = &quot;&quot;, breaks = 10) hist(meta$chao, main = &quot;Chao richness&quot;, xlab = &quot;&quot;, breaks = 15) hist(meta$ace, main = &quot;ACE richness&quot;, xlab = &quot;&quot;, breaks = 15) None of the data are normally distributed. Simpson diversity is very often skewed as seen in this histogram, so we’ll calculate 1/Simpson and plot the metrics again. # Creating a 2x2 environment par(mfrow = c(2,2)) # Plotting the four metrics again hist(meta$shannon, main = &quot;Shannon diversity&quot;, xlab = &quot;&quot;, breaks = 10) hist(1/meta$simpson, main = &quot;Inverse Simpson diversity&quot;, xlab = &quot;&quot;, breaks = 10) hist(meta$chao, main = &quot;Chao richness&quot;, xlab = &quot;&quot;, breaks = 15) hist(meta$ace, main = &quot;ACE richness&quot;, xlab = &quot;&quot;, breaks = 15) Now the Simpson diversity is distributed similarly to the other richness metrics. Next, we’ll test the four metrics for normal distribution. shapiro.test(meta$shannon) ## ## Shapiro-Wilk normality test ## ## data: meta$shannon ## W = 0.91511, p-value = 0.0456 shapiro.test(1/meta$simpson) ## ## Shapiro-Wilk normality test ## ## data: 1/meta$simpson ## W = 0.74821, p-value = 4.69e-05 shapiro.test(meta$chao) ## ## Shapiro-Wilk normality test ## ## data: meta$chao ## W = 0.80636, p-value = 0.0003749 shapiro.test(meta$ace) ## ## Shapiro-Wilk normality test ## ## data: meta$ace ## W = 0.83017, p-value = 0.0009573 None of the richness metrics are normally distributed, which was to be expected from the graphs we’ve seen. So we cannot run any tests that assume the data is normally distributed. For illustration purposes, we’ll run the ANOVA test with the Shannon’s diversity because that’s the closest to normally distributed. We’ll look at if age impacts the Shannon diversity of the fecal microbiota. aov.shannon.age = aov(shannon ~ AgeGroup, data = meta) summary(aov.shannon.age) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## AgeGroup 2 42.98 21.489 103.4 1.35e-11 *** ## Residuals 21 4.36 0.208 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 We’ll run Tukey’s honest significance test to do pairwise comparisons between groups and correct for multiple comparisons. TukeyHSD(aov.shannon.age) ## Tukey multiple comparisons of means ## 95% family-wise confidence level ## ## Fit: aov(formula = shannon ~ AgeGroup, data = meta) ## ## $AgeGroup ## diff lwr upr p adj ## 2w-1yr -3.270063 -3.8446230 -2.695503 0.0e+00 ## 8w-1yr -1.830903 -2.4054628 -1.256342 2.0e-07 ## 8w-2w 1.439160 0.8646001 2.013720 8.5e-06 It’s clear that all age groups have significantly different diversity. In a plot, we can clearly see that diversity increases with ages. # Re-ordering the groups meta$AgeGroup.ord = factor(meta$AgeGroup, c(&quot;2w&quot;, &quot;8w&quot;, &quot;1yr&quot;)) # Returning the plot area to 1x1 par(mfrow = c(1,1)) # Plotting the diversity boxplot(shannon ~ AgeGroup.ord, data = meta, ylab = &quot;Shannon&#39;s diversity&quot;, xlab = &quot;Age group&quot;) # Added the xlab myself because it looks better :) To illustrate some non-parametric tests, we’ll use Chao’s richness estimate. Age is categorical, so we’ll use Kruskal-Wallis. kruskal.test(chao ~ AgeGroup, data = meta) ## ## Kruskal-Wallis rank sum test ## ## data: chao by AgeGroup ## Kruskal-Wallis chi-squared = 19.28, df = 2, p-value = 6.507e-05 We can also test pairwise within age groups with Wilcoxon Rank Sum Tests. pairwise.wilcox.test(meta$chao, meta$AgeGroup, p.adjust.method = &quot;fdr&quot;) ## ## Pairwise comparisons using Wilcoxon rank sum exact test ## ## data: meta$chao and meta$AgeGroup ## ## 1yr 2w ## 2w 0.00023 - ## 8w 0.00023 0.00186 ## ## P value adjustment method: fdr Just like the diversity, richness also increases with age. # Creating a 1x1 plot environment par(mfrow = c(1,1)) # Plotting the richness boxplot(chao ~ AgeGroup.ord, data = meta, ylab = &quot;Chao richness&quot;, xlab = &quot;Age group&quot;) # Again, added the xlab myself for aesthetics :) Average Daily Gain is a continuous variable, so we’ll use a linear model to visualise it. We’ll use Shannon’s diversity again to run some tests that are meant for normally distributed data. We’ll take a look at if the ADG impacts the Shannon diversity of the fecal microbiota. glm.shannon.ADG = glm(shannon ~ ADGKG, data = meta) summary(glm.shannon.ADG) ## ## Call: ## glm(formula = shannon ~ ADGKG, data = meta) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -2.49110 -1.11216 -0.01749 1.53658 1.84728 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 3.62565 1.01390 3.576 0.00169 ** ## ADGKG -0.03407 0.97805 -0.035 0.97253 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for gaussian family taken to be 2.151815) ## ## Null deviance: 47.343 on 23 degrees of freedom ## Residual deviance: 47.340 on 22 degrees of freedom ## AIC: 90.412 ## ## Number of Fisher Scoring iterations: 2 This shows that the intercept of our model is signficantly different from 0, bu the slope is not, and the slope is our variable of interest. Next, let’s plot the glm. plot(shannon ~ ADGKG, data = meta) abline(glm.shannon.ADG) To illustrate non-normally distributed data, we’ll use Chao’s richness estimate again. We’ll first use the Gaussian distribution, but we already know this isn’t a good fit. gaussian.chao.adg = glm(chao ~ADGKG, data = meta, family = &quot;gaussian&quot;) par(mfrow = c(1,2)) plot(gaussian.chao.adg, which = c(1,2)) Next, we’ll plot the quasipoisson distribuiton. qp.chao.ADG = glm(chao ~ ADGKG, data = meta, family = &quot;quasipoisson&quot;) par(mfrow = c(1,2)) plot(qp.chao.ADG, which = c(1,2)) The quasipoisson distribution fits much better than the Gaussian distribution, so we’ll use quasipoisson for further calculations. summary(qp.chao.ADG) ## ## Call: ## glm(formula = chao ~ ADGKG, family = &quot;quasipoisson&quot;, data = meta) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -24.36 -17.05 -10.66 18.81 26.91 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 6.4528 0.5561 11.605 7.54e-11 *** ## ADGKG -0.1859 0.5438 -0.342 0.736 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for quasipoisson family taken to be 374.2485) ## ## Null deviance: 8117.2 on 23 degrees of freedom ## Residual deviance: 8074.4 on 22 degrees of freedom ## AIC: NA ## ## Number of Fisher Scoring iterations: 5 We’ll plot Chao and ADGKG again, to look at the correlation. par(mfrow = c(1,1)) plot(log(chao) ~ ADGKG, data = meta, ylab = &quot;ln(Chao&#39;s richness)&quot;) abline(qp.chao.ADG) Looking at the graph, there is nog significant correlation between Chao’s richness and the Average Daily Gain. To test if age and ADG impacts diversity, we’ll conduct an ANOVA test. aov.shannon.all = aov(shannon ~ AgeGroup*ADGKG, data = meta) summary(aov.shannon.all) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## AgeGroup 2 42.98 21.489 95.472 2.61e-10 *** ## ADGKG 1 0.05 0.054 0.239 0.631 ## AgeGroup:ADGKG 2 0.26 0.130 0.576 0.572 ## Residuals 18 4.05 0.225 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 We can see that the interaction between age and ADG does not significantly impact Shannon’s diversity, so we’ll remove that variable and run the test again. aov.shannon.all2 = aov(shannon ~ AgeGroup+ADGKG, data = meta) summary(aov.shannon.all2) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## AgeGroup 2 42.98 21.489 99.70 3.96e-11 *** ## ADGKG 1 0.05 0.054 0.25 0.623 ## Residuals 20 4.31 0.216 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 This test tells us that only age impacts Shannon’s diversity significantly, but we do not know which age groups differ significantly from eachother. To test this, we can run TukeyHSD with just age. TukeyHSD(aov.shannon.all) ## Tukey multiple comparisons of means ## 95% family-wise confidence level ## ## Fit: aov(formula = shannon ~ AgeGroup * ADGKG, data = meta) ## ## $AgeGroup ## diff lwr upr p adj ## 2w-1yr -3.270063 -3.875469 -2.664657 0.00e+00 ## 8w-1yr -1.830903 -2.436309 -1.225496 1.20e-06 ## 8w-2w 1.439160 0.833754 2.044567 2.81e-05 With this test, however, ADGKG is ignored because it’s continuous. We’ll run the glm instead. glm.shannon.all = glm(shannon ~ AgeGroup*ADGKG, data = meta) summary(glm.shannon.all) ## ## Call: ## glm(formula = shannon ~ AgeGroup * ADGKG, data = meta) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -1.0301 -0.2468 0.0894 0.1572 0.7624 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 5.7123 2.5928 2.203 0.0409 * ## AgeGroup2w -3.3969 2.6197 -1.297 0.2111 ## AgeGroup8w -2.9610 2.7554 -1.075 0.2967 ## ADGKG -0.4481 2.7599 -0.162 0.8728 ## AgeGroup2w:ADGKG 0.1228 2.7848 0.044 0.9653 ## AgeGroup8w:ADGKG 1.0750 2.8763 0.374 0.7130 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for gaussian family taken to be 0.22508) ## ## Null deviance: 47.3425 on 23 degrees of freedom ## Residual deviance: 4.0514 on 18 degrees of freedom ## AIC: 39.413 ## ## Number of Fisher Scoring iterations: 2 We can see that none of the interaction terms, which are AgeGroup2w:ADGKG and AgeGroup8w:ADGKG, are significant. So we’ll remove these, by changing AgeGroup*ADGKG to AgeGroup+ADGKG, and run the glm again. glm.shannon.all2 = glm(shannon ~ AgeGroup+ADGKG, data = meta) summary(glm.shannon.all2) ## ## Call: ## glm(formula = shannon ~ AgeGroup + ADGKG, data = meta) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -0.95299 -0.25858 0.07643 0.30409 0.74487 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 5.4459 0.3487 15.619 1.14e-12 *** ## AgeGroup2w -3.2760 0.2324 -14.094 7.55e-12 *** ## AgeGroup8w -1.7989 0.2408 -7.471 3.30e-07 *** ## ADGKG -0.1639 0.3281 -0.500 0.623 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for gaussian family taken to be 0.2155447) ## ## Null deviance: 47.3425 on 23 degrees of freedom ## Residual deviance: 4.3109 on 20 degrees of freedom ## AIC: 36.903 ## ## Number of Fisher Scoring iterations: 2 Now that we’ve removed the interaction terms, the glm model shows age as significant. This can also be done with non-normally distributed data, like Chao’s richness. qp.chao.all = glm(chao ~ AgeGroup*ADGKG, data = meta, family = &quot;quasipoisson&quot;) summary(qp.chao.all) ## ## Call: ## glm(formula = chao ~ AgeGroup * ADGKG, family = &quot;quasipoisson&quot;, ## data = meta) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -7.774 -3.430 -0.140 3.692 5.277 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 6.99825 0.71122 9.840 1.14e-08 *** ## AgeGroup2w -1.61539 0.75272 -2.146 0.0458 * ## AgeGroup8w -2.24498 0.86846 -2.585 0.0187 * ## ADGKG 0.01751 0.75699 0.023 0.9818 ## AgeGroup2w:ADGKG -0.42295 0.80094 -0.528 0.6039 ## AgeGroup8w:ADGKG 0.86269 0.86550 0.997 0.3321 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for quasipoisson family taken to be 18.86331) ## ## Null deviance: 8117.2 on 23 degrees of freedom ## Residual deviance: 348.5 on 18 degrees of freedom ## AIC: NA ## ## Number of Fisher Scoring iterations: 4 Just like the Shannon’s diversity, the interaction terms are not significant, so we’ll remove those and run the glm again. qp.chao.all2 = glm(chao ~ AgeGroup+ADGKG, data = meta, family = &quot;quasipoisson&quot;) summary(qp.chao.all2) ## ## Call: ## glm(formula = chao ~ AgeGroup + ADGKG, family = &quot;quasipoisson&quot;, ## data = meta) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -7.783 -3.452 -1.378 3.744 8.184 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 7.03944 0.23567 29.870 &lt; 2e-16 *** ## AgeGroup2w -1.98090 0.14862 -13.329 2.08e-11 *** ## AgeGroup8w -1.24286 0.11926 -10.422 1.57e-09 *** ## ADGKG -0.02643 0.24530 -0.108 0.915 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for quasipoisson family taken to be 23.74583) ## ## Null deviance: 8117.20 on 23 degrees of freedom ## Residual deviance: 476.31 on 20 degrees of freedom ## AIC: NA ## ## Number of Fisher Scoring iterations: 4 As we can see, age is now significant for richness aswell. We sampled the same animals over time, so this is a repeated measures design. We can add this component with (1|animal) in the lmer function. rm.shannon.all = lmer(shannon ~ AgeGroup+ADGKG + (1|Animal), data = meta) summary(rm.shannon.all) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: shannon ~ AgeGroup + ADGKG + (1 | Animal) ## Data: meta ## ## REML criterion at convergence: 32.4 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -1.83117 -0.45932 0.09539 0.49972 1.53368 ## ## Random effects: ## Groups Name Variance Std.Dev. ## Animal (Intercept) 0.03793 0.1948 ## Residual 0.17819 0.4221 ## Number of obs: 24, groups: Animal, 8 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 5.3906 0.3520 15.313 ## AgeGroup2w -3.2739 0.2114 -15.486 ## AgeGroup8w -1.8104 0.2208 -8.201 ## ADGKG -0.1049 0.3321 -0.316 ## ## Correlation of Fixed Effects: ## (Intr) AgGrp2 AgGrp8 ## AgeGroup2w -0.350 ## AgeGroup8w -0.027 0.461 ## ADGKG -0.884 0.057 -0.293 Very little, 0.0379, of the variance is explained by the animal random effect. This means that we don’t have to include the repeated measures in our final model, but it did need to be checked! In conclusion on the alpha diversity: The diversity and richness of the fecal microbiota increases as the dairy cows age. Animal growth, measured by ADG, does not correlate with the diversity or richness of the fecal community. Looking at the beta diversity Beta diversity looks at the dissimilarity between samples, instead of within a sample, like the alpha diversity. First, we’ll calculate the non-metric multidimensional scaling using the Bray-Curtis metric. This metric takes into account the presence or absence of OTU’s and the abundance of the OTU’s that are present in the samples. So, this metric looks at richness and diversity. BC.nmds = metaMDS(OTU.clean, distance = &quot;bray&quot;, k=2, trymax = 1000) ## Square root transformation ## Wisconsin double standardization ## Run 0 stress 0.06208119 ## Run 1 stress 0.06210577 ## ... Procrustes: rmse 0.00142196 max resid 0.005448642 ## ... Similar to previous best ## Run 2 stress 0.06208123 ## ... Procrustes: rmse 0.0002939818 max resid 0.0006667466 ## ... Similar to previous best ## Run 3 stress 0.06208111 ## ... New best solution ## ... Procrustes: rmse 0.000204731 max resid 0.000465473 ## ... Similar to previous best ## Run 4 stress 0.0620811 ## ... New best solution ## ... Procrustes: rmse 1.986518e-05 max resid 4.33287e-05 ## ... Similar to previous best ## Run 5 stress 0.06208117 ## ... Procrustes: rmse 5.794984e-05 max resid 0.0001305115 ## ... Similar to previous best ## Run 6 stress 0.06208113 ## ... Procrustes: rmse 3.672359e-05 max resid 8.23805e-05 ## ... Similar to previous best ## Run 7 stress 0.06210572 ## ... Procrustes: rmse 0.001378329 max resid 0.005368037 ## ... Similar to previous best ## Run 8 stress 0.06210378 ## ... Procrustes: rmse 0.001413908 max resid 0.005105586 ## ... Similar to previous best ## Run 9 stress 0.06208125 ## ... Procrustes: rmse 0.0001224896 max resid 0.0002747291 ## ... Similar to previous best ## Run 10 stress 0.06208111 ## ... Procrustes: rmse 1.212188e-05 max resid 2.522293e-05 ## ... Similar to previous best ## Run 11 stress 0.06208121 ## ... Procrustes: rmse 0.0002127404 max resid 0.0004849115 ## ... Similar to previous best ## Run 12 stress 0.06210373 ## ... Procrustes: rmse 0.001425856 max resid 0.005115974 ## ... Similar to previous best ## Run 13 stress 0.3701749 ## Run 14 stress 0.06210382 ## ... Procrustes: rmse 0.001409512 max resid 0.005096637 ## ... Similar to previous best ## Run 15 stress 0.06208124 ## ... Procrustes: rmse 9.356523e-05 max resid 0.0002029152 ## ... Similar to previous best ## Run 16 stress 0.06210382 ## ... Procrustes: rmse 0.001453464 max resid 0.005117477 ## ... Similar to previous best ## Run 17 stress 0.06210562 ## ... Procrustes: rmse 0.001356805 max resid 0.005299213 ## ... Similar to previous best ## Run 18 stress 0.06208121 ## ... Procrustes: rmse 8.948438e-05 max resid 0.0001972643 ## ... Similar to previous best ## Run 19 stress 0.06208123 ## ... Procrustes: rmse 0.0001043305 max resid 0.0002338428 ## ... Similar to previous best ## Run 20 stress 0.06210572 ## ... Procrustes: rmse 0.00138274 max resid 0.005378219 ## ... Similar to previous best ## *** Solution reached We’ve reached a convergent solution at around 20 iterations, and the stress is very low, 0.06. That means that 2 axis are sufficient to plot our data. We’ll plot our data with different colors for each age group. par(mfrow = c(1,1)) # Creating a blank plot for the nmds plot(BC.nmds, type = &quot;n&quot;, main = &quot;Bray-Curtis&quot;) # Adding the points points(BC.nmds, display = &quot;sites&quot;, pch = 20, col=c(&quot;blue&quot;, &quot;green&quot;, &quot;red&quot;))[meta$AgeGroup] # [Meta$AgeGroup] buiten haakjes gehaald ## NULL # Adding a legend legend(-5.5, 2.5, legend = c(&quot;2w&quot;, &quot;8w&quot;, &quot;1yr&quot;), col=c(&quot;green&quot;, &quot;red&quot;, &quot;blue&quot;), pch = 20) We can also calculate the nMDS for the Jaccard metric. This metric only looks at the presence or absence of OTU’s, so it only looks at richness. J.nmds = metaMDS(OTU.clean, distance = &quot;jaccard&quot;, k=2, trymax = 1000) ## Square root transformation ## Wisconsin double standardization ## Run 0 stress 0.06208109 ## Run 1 stress 0.0620812 ## ... Procrustes: rmse 0.000177083 max resid 0.0003999569 ## ... Similar to previous best ## Run 2 stress 0.06210582 ## ... Procrustes: rmse 0.001409216 max resid 0.005429768 ## ... Similar to previous best ## Run 3 stress 0.06210567 ## ... Procrustes: rmse 0.00137946 max resid 0.005369397 ## ... Similar to previous best ## Run 4 stress 0.06208119 ## ... Procrustes: rmse 0.0001744131 max resid 0.0003942546 ## ... Similar to previous best ## Run 5 stress 0.06208115 ## ... Procrustes: rmse 0.000130016 max resid 0.0002909929 ## ... Similar to previous best ## Run 6 stress 0.06208112 ## ... Procrustes: rmse 0.0001066234 max resid 0.0002384603 ## ... Similar to previous best ## Run 7 stress 0.0620811 ## ... Procrustes: rmse 9.468274e-05 max resid 0.0002141725 ## ... Similar to previous best ## Run 8 stress 0.0621059 ## ... Procrustes: rmse 0.001426217 max resid 0.005460826 ## ... Similar to previous best ## Run 9 stress 0.06208124 ## ... Procrustes: rmse 0.0002015441 max resid 0.0004545264 ## ... Similar to previous best ## Run 10 stress 0.0620812 ## ... Procrustes: rmse 0.0001797232 max resid 0.0004060386 ## ... Similar to previous best ## Run 11 stress 0.06208109 ## ... New best solution ## ... Procrustes: rmse 6.139566e-05 max resid 0.0001371443 ## ... Similar to previous best ## Run 12 stress 0.0621038 ## ... Procrustes: rmse 0.001406932 max resid 0.005095216 ## ... Similar to previous best ## Run 13 stress 0.06208126 ## ... Procrustes: rmse 0.0001414878 max resid 0.0003183287 ## ... Similar to previous best ## Run 14 stress 0.06208108 ## ... New best solution ## ... Procrustes: rmse 3.770942e-05 max resid 7.95009e-05 ## ... Similar to previous best ## Run 15 stress 0.06210568 ## ... Procrustes: rmse 0.001379045 max resid 0.005369661 ## ... Similar to previous best ## Run 16 stress 0.06208111 ## ... Procrustes: rmse 8.244032e-05 max resid 0.0001835168 ## ... Similar to previous best ## Run 17 stress 0.06208123 ## ... Procrustes: rmse 0.0001586643 max resid 0.0003545319 ## ... Similar to previous best ## Run 18 stress 0.06208122 ## ... Procrustes: rmse 0.0001644494 max resid 0.0003672165 ## ... Similar to previous best ## Run 19 stress 0.06208112 ## ... Procrustes: rmse 7.816312e-05 max resid 0.0001743423 ## ... Similar to previous best ## Run 20 stress 0.0620811 ## ... Procrustes: rmse 7.313823e-05 max resid 0.0001625506 ## ... Similar to previous best ## *** Solution reached With this metric, we’ve also reached a convergent solution after 20 iterations. The stress is also very low for this metric, 0.06. So, we’ll plot this metric with 2 axis aswell. plot(J.nmds, type = &quot;n&quot;, main = &quot;Jaccard&quot;) points(J.nmds, display = &quot;sites&quot;, pch = 20, col=c(&quot;blue&quot;, &quot;green&quot;, &quot;red&quot;))[meta$AgeGroup] ## NULL legend(-3, 1.5, legend=c(&quot;2w&quot;, &quot;8w&quot;, &quot;1yr&quot;), col = c(&quot;green&quot;, &quot;red&quot;, &quot;blue&quot;), pch = 20) The values in the plot are somewhat different, but the distributions are very similar. That’s because Jaccard = 2xBray-Curtis/(1+Bray-Curtis). We can also plot the standard error ellipses of the nMDS data. We’ll plot the 99% confidence interval of the Bray-Curtis metric. plot(BC.nmds, type = &quot;n&quot;, main = &quot;Bray-Curtis&quot;) legend(-5.5, 2.5, legend = c(&quot;2w&quot;, &quot;8w&quot;, &quot;1yr&quot;), col = c(&quot;green&quot;, &quot;red&quot;, &quot;blue&quot;), pch = 20) # Ellipse for 2 weeks ordiellipse(BC.nmds, groups = meta$AgeGroup, display = &quot;sites&quot;, kind = &quot;se&quot;, conf = 0.99, label = FALSE, col = &quot;green&quot;, draw = &quot;polygon&quot;, alpha = 200, show.groups = c(&quot;2w&quot;), border = FALSE) # Ellipse for 8 weeks ordiellipse(BC.nmds, groups = meta$AgeGroup, display = &quot;sites&quot;, kind = &quot;se&quot;, conf = 0.99, label = FALSE, col = &quot;red&quot;, draw = &quot;polygon&quot;, alpha = 200, show.groups = c(&quot;8w&quot;), border = FALSE) # ELLipse for 1 year ordiellipse(BC.nmds, groups = meta$AgeGroup, display = &quot;sites&quot;, kind = &quot;se&quot;, conf = 0.99, label = FALSE, col = &quot;blue&quot;, draw = &quot;polygon&quot;, alpha = 200, show.groups = c(&quot;1yr&quot;), border = FALSE) If the stress is high, over 0.3, it’s better to increase to 3 axes. We’ll first calculate the Bray-Curtis nMDS for a 3-axis plot. BC.nmds.3D = metaMDS(OTU.clean, distance = &quot;bray&quot;, k=3, trymax=1000) ## Square root transformation ## Wisconsin double standardization ## Run 0 stress 0.04686211 ## Run 1 stress 0.04741561 ## Run 2 stress 0.04673316 ## ... New best solution ## ... Procrustes: rmse 0.01078619 max resid 0.03453509 ## Run 3 stress 0.05061342 ## Run 4 stress 0.04740116 ## Run 5 stress 0.04984351 ## Run 6 stress 0.04747471 ## Run 7 stress 0.05226505 ## Run 8 stress 0.0529536 ## Run 9 stress 0.04741183 ## Run 10 stress 0.04575764 ## ... New best solution ## ... Procrustes: rmse 0.03871705 max resid 0.1297458 ## Run 11 stress 0.05084344 ## Run 12 stress 0.04719045 ## Run 13 stress 0.04864532 ## Run 14 stress 0.04750072 ## Run 15 stress 0.04793837 ## Run 16 stress 0.04579474 ## ... Procrustes: rmse 0.004492898 max resid 0.01438546 ## Run 17 stress 0.05069325 ## Run 18 stress 0.04857979 ## Run 19 stress 0.05058111 ## Run 20 stress 0.04859455 ## Run 21 stress 0.04996549 ## Run 22 stress 0.04739851 ## Run 23 stress 0.04747497 ## Run 24 stress 0.04675354 ## Run 25 stress 0.04747484 ## Run 26 stress 0.04861683 ## Run 27 stress 0.04575768 ## ... Procrustes: rmse 0.0001087933 max resid 0.0001902161 ## ... Similar to previous best ## *** Solution reached We’ll extract the x, y and z for the nMDS, and then plot them. BCxyz = scores(BC.nmds.3D, display = &quot;sites&quot;) BCxyz ## NMDS1 NMDS2 NMDS3 ## 5017.1yr.F -4.7877193 0.32878559 -0.204579523 ## 5017.2w.F 3.1847627 0.05697846 1.484325743 ## 5017.8w.F 1.0503489 -2.11932201 -1.217100783 ## 5020.1yr.F -4.7466509 0.24479143 -0.001927473 ## 5020.2w.F 3.4956397 -1.01621364 1.008439783 ## 5020.8w.F 1.5785763 -1.92688899 0.465285369 ## 5026.1yr.F -4.7617021 0.20961333 0.209854984 ## 5026.2w.F 3.3964195 1.09611959 -0.615338225 ## 5026.8w.F 3.1475032 2.07012741 1.477070476 ## 5031.1yr.F -4.7920071 0.44153808 0.196685523 ## 5031.2w.F 3.3507672 0.48092133 -1.491382237 ## 5031.8w.F 0.8516766 -1.63544389 0.254264412 ## 5037.1yr.F -4.8418075 0.48746059 -0.004313703 ## 5037.2w.F 3.6570393 0.26299035 -0.511188778 ## 5037.8w.F 3.1287853 -0.82431199 -0.025514353 ## 5041.1yr.F -4.7617047 0.28520072 0.060756551 ## 5041.2w.F 3.1646155 2.42901236 -1.216761595 ## 5041.8w.F 1.0838533 -2.57296922 -0.236134615 ## 5045.1yr.F -4.7419263 0.16694129 0.005568155 ## 5045.2w.F 1.5045514 3.11037881 -0.462668248 ## 5045.8w.F 1.4782189 -2.16474462 -0.450092185 ## 5053.1yr.F -4.8160856 0.39888230 -0.016335985 ## 5053.2w.F 3.2925437 2.29778435 0.813017161 ## 5053.8w.F 0.8843018 -2.10763164 0.478069543 plot_ly(x=BCxyz[,1], y=BCxyz[,2], z=BCxyz[,3], type = &quot;scatter3d&quot;, mode = &quot;markers&quot;, color = meta$AgeGroup, colors = c(&quot;blue&quot;, &quot;green&quot;, &quot;red&quot;)) 3D plots are difficult to interpret in articles, so many authors choose to create two 2D plots instead. par(mfrow = c(1,2)) # Plotting axis 1 and 2, which are x and y plot(BCxyz[,1], BCxyz[,2], main = &quot;Bray-Curtis 1:2&quot;, pch = 20, col = c(&quot;blue&quot;, &quot;green&quot;, &quot;red&quot;))[meta$AgeGroup] ## NULL legend(-5.4, 3, legend = c(&quot;2w&quot;, &quot;8w&quot;, &quot;1yr&quot;), col = c(&quot;green&quot;, &quot;red&quot;, &quot;blue&quot;), pch = 20) # Plotting axis 1 and 3, which are x and z plot(BCxyz[,1], BCxyz[,3], main = &quot;Bray-Curtis 1:3&quot;, pch = 20, col = c(&quot;blue&quot;, &quot;green&quot;, &quot;red&quot;))[meta$AgeGroup] ## NULL The most common type of beta-diversity metric is UniFrac. This metric takes phylogenetic relationships into account, as opposed to Bray-Curtis and Jaccard. So, with UniFrac, samples with different OTU’s from the same genus will be more similar than samples with OTU’s from different genera. The drawback of UniFrac is that it’s sensitive to low abundance OTU’s. To plot UniFrac, we first have to make a phyloseq object. That means we need OTU.clean, meta and tax.clean data. After we’ve created the three separate objects, we’ll merge them into one. OTU.UF = otu_table(as.matrix(OTU.clean), taxa_are_rows = FALSE) tax.UF = tax_table(as.matrix(tax.clean)) meta.UF = sample_data(meta) # Merging them into an object of class phyloseq physeq = phyloseq(OTU.UF, tax.UF, meta.UF) To add the phylogenetic component to UniFrac, we need a rooted phylogenetic tree of the OTU’s. In this workshop, it had already been calculated and stored in the dataset ‘NJ.tree.Rdata’. So, we’ll load this data and add it to the physeq object. Then, we’ll look at the tree and its components. load(&quot;Data/NJ.tree.Rdata&quot;) # Downloaded it from GitHub and stored it in the folder &quot;Data&quot; physeq.tree = merge_phyloseq(physeq, NJ.tree) physeq.tree ## phyloseq-class experiment-level object ## otu_table() OTU Table: [ 5002 taxa and 24 samples ] ## sample_data() Sample Data: [ 24 samples by 9 sample variables ] ## tax_table() Taxonomy Table: [ 5002 taxa by 7 taxonomic ranks ] ## phy_tree() Phylogenetic Tree: [ 5002 tips and 5000 internal nodes ] Next, we’ll calculate the weighted UniFrac and ordinate it into nMDS. wUF.ordu = ordinate(physeq.tree, method = &quot;NMDS&quot;, distance = &quot;unifrac&quot;, weighted = TRUE) ## Run 0 stress 0.08645307 ## Run 1 stress 0.08645305 ## ... New best solution ## ... Procrustes: rmse 1.95726e-05 max resid 5.360447e-05 ## ... Similar to previous best ## Run 2 stress 0.1335688 ## Run 3 stress 0.1462923 ## Run 4 stress 0.08645302 ## ... New best solution ## ... Procrustes: rmse 0.0003084251 max resid 0.0008232998 ## ... Similar to previous best ## Run 5 stress 0.08645296 ## ... New best solution ## ... Procrustes: rmse 0.0002326256 max resid 0.0006198192 ## ... Similar to previous best ## Run 6 stress 0.1157451 ## Run 7 stress 0.1143564 ## Run 8 stress 0.1317675 ## Run 9 stress 0.08645297 ## ... Procrustes: rmse 0.0001396108 max resid 0.0003650213 ## ... Similar to previous best ## Run 10 stress 0.08808604 ## Run 11 stress 0.08645293 ## ... New best solution ## ... Procrustes: rmse 5.607187e-05 max resid 0.000148279 ## ... Similar to previous best ## Run 12 stress 0.115745 ## Run 13 stress 0.08645302 ## ... Procrustes: rmse 0.0001812108 max resid 0.00048756 ## ... Similar to previous best ## Run 14 stress 0.1143564 ## Run 15 stress 0.08659154 ## ... Procrustes: rmse 0.004236648 max resid 0.01797805 ## Run 16 stress 0.1295293 ## Run 17 stress 0.08645307 ## ... Procrustes: rmse 0.0001978456 max resid 0.0005319125 ## ... Similar to previous best ## Run 18 stress 0.1347949 ## Run 19 stress 0.08645294 ## ... Procrustes: rmse 1.302835e-05 max resid 3.061646e-05 ## ... Similar to previous best ## Run 20 stress 0.08808611 ## *** Solution reached Let’s plot the UniFrac nMDS. par(mfrow = c(1,1)) plot(wUF.ordu, type = &quot;n&quot;, main = &quot;Weighted UniFrac&quot;) points(wUF.ordu, pch = 20, display = &quot;sites&quot;, col = c(&quot;blue&quot;, &quot;green&quot;, &quot;red&quot;))[meta$AgeGroup] ## NULL legend(0.3, 0.15, legend = c(&quot;2w&quot;, &quot;8w&quot;, &quot;1yr&quot;), col = c(&quot;green&quot;, &quot;red&quot;, &quot;blue&quot;), pch = 20) We can also plot it with ggplot2. plot_ordination(physeq.tree, wUF.ordu, type = &quot;sites&quot;, color = &quot;AgeGroup&quot;)+ scale_colour_manual(values = c(&quot;2w&quot;=&quot;green&quot;, &quot;8w&quot;=&quot;red&quot;, &quot;1yr&quot;=&quot;blue&quot;))+ theme_bw()+ ggtitle(&quot;Weighted UniFrac&quot;) The Unweighted UniFrac can also be calculated and plotted. uwUF.ordu = ordinate(physeq.tree, method = &quot;NMDS&quot;, distance = &quot;unifrac&quot;, weighted = FALSE) ## Run 0 stress 9.695153e-05 ## Run 1 stress 9.657832e-05 ## ... New best solution ## ... Procrustes: rmse 7.750783e-05 max resid 0.0002776914 ## ... Similar to previous best ## Run 2 stress 9.871795e-05 ## ... Procrustes: rmse 8.086551e-05 max resid 0.0002819207 ## ... Similar to previous best ## Run 3 stress 9.488623e-05 ## ... New best solution ## ... Procrustes: rmse 7.261501e-05 max resid 0.0002642816 ## ... Similar to previous best ## Run 4 stress 9.862006e-05 ## ... Procrustes: rmse 1.701217e-05 max resid 5.025527e-05 ## ... Similar to previous best ## Run 5 stress 9.806631e-05 ## ... Procrustes: rmse 0.0001070473 max resid 0.0002353732 ## ... Similar to previous best ## Run 6 stress 9.757454e-05 ## ... Procrustes: rmse 3.985665e-05 max resid 0.0001388531 ## ... Similar to previous best ## Run 7 stress 9.826177e-05 ## ... Procrustes: rmse 9.722135e-05 max resid 0.0002191936 ## ... Similar to previous best ## Run 8 stress 9.695708e-05 ## ... Procrustes: rmse 7.448687e-05 max resid 0.0002751687 ## ... Similar to previous best ## Run 9 stress 9.907648e-05 ## ... Procrustes: rmse 9.310993e-05 max resid 0.0002388289 ## ... Similar to previous best ## Run 10 stress 9.984534e-05 ## ... Procrustes: rmse 3.384419e-05 max resid 0.0001260377 ## ... Similar to previous best ## Run 11 stress 9.684607e-05 ## ... Procrustes: rmse 0.0001319037 max resid 0.0003356478 ## ... Similar to previous best ## Run 12 stress 9.69891e-05 ## ... Procrustes: rmse 8.404145e-06 max resid 2.447679e-05 ## ... Similar to previous best ## Run 13 stress 0.0002969569 ## ... Procrustes: rmse 0.0003866364 max resid 0.0006715474 ## ... Similar to previous best ## Run 14 stress 9.723199e-05 ## ... Procrustes: rmse 3.731826e-05 max resid 0.0001336343 ## ... Similar to previous best ## Run 15 stress 9.99257e-05 ## ... Procrustes: rmse 0.0001270356 max resid 0.0003614341 ## ... Similar to previous best ## Run 16 stress 9.955355e-05 ## ... Procrustes: rmse 6.056256e-05 max resid 0.0001673759 ## ... Similar to previous best ## Run 17 stress 9.589429e-05 ## ... Procrustes: rmse 1.686683e-05 max resid 4.596185e-05 ## ... Similar to previous best ## Run 18 stress 9.633493e-05 ## ... Procrustes: rmse 3.660483e-05 max resid 0.0001324208 ## ... Similar to previous best ## Run 19 stress 9.921893e-05 ## ... Procrustes: rmse 1.085938e-05 max resid 1.669484e-05 ## ... Similar to previous best ## Run 20 stress 9.637055e-05 ## ... Procrustes: rmse 6.450683e-05 max resid 0.0001970587 ## ... Similar to previous best ## *** Solution reached plot_ordination(physeq.tree, uwUF.ordu, type = &quot;sites&quot;, color = &quot;AgeGroup&quot;)+ scale_colour_manual(values = c(&quot;2w&quot; = &quot;green&quot;, &quot;8w&quot; = &quot;red&quot;, &quot;1yr&quot; = &quot;blue&quot;))+ theme_bw()+ ggtitle(&quot;Unweighted UniFrac&quot;) We can also plot the ellipses of the Weighted UniFrac distances. plot(wUF.ordu, type = &quot;n&quot;, main = &quot;Weighted UniFrac&quot;) legend(0.3, 0.15, legend = c(&quot;2w&quot;,&quot;8w&quot;,&quot;1yr&quot;), col = c(&quot;pink&quot;, &quot;purple&quot;, &quot;blue&quot;), pch = 20) # Ellipse for 2 weeks ordiellipse(wUF.ordu, groups = meta$AgeGroup, display = &quot;sites&quot;, kind = &quot;se&quot;, conf = 0.99, label = FALSE, col = &quot;pink&quot;, draw = &quot;polygon&quot;, alpha = 200, show.groups = c(&quot;2w&quot;), border = FALSE) # Ellipse for 8 weeks ordiellipse(wUF.ordu, groups = meta$AgeGroup, display = &quot;sites&quot;, kind = &quot;se&quot;, conf = 0.99, label = FALSE, col = &quot;purple&quot;, draw = &quot;polygon&quot;, alpha = 200, show.groups = c(&quot;8w&quot;), border = FALSE) # Ellipse for 1 year ordiellipse(wUF.ordu, groups = meta$AgeGroup, display = &quot;sites&quot;, kind = &quot;se&quot;, conf = 0.99, label = FALSE, col = &quot;blue&quot;, draw = &quot;polygon&quot;, alpha = 200, show.groups = c(&quot;1yr&quot;), border = FALSE) Ellipses can also be plotted with ggplot2, although they look a bit different. plot_ordination(physeq.tree, wUF.ordu, type = &quot;sites&quot;, color = &quot;AgeGroup&quot;)+ scale_colour_manual(values = c(&quot;2w&quot; = &quot;pink&quot;, &quot;8w&quot; = &quot;purple&quot;, &quot;1yr&quot; = &quot;blue&quot;))+ theme_bw()+ stat_ellipse()+ ggtitle(&quot;Weighted UniFrac&quot;) We can calculate UniFrac distances with UniFrac and ordinate it for 3-axes with metaMDS. wUF.dist = UniFrac(physeq.tree, weighted = TRUE, normalized = TRUE) wUF.nmds.3D = metaMDS(wUF.dist, method = &quot;NMDS&quot;, k=3) ## Run 0 stress 0.04217394 ## Run 1 stress 0.05952403 ## Run 2 stress 0.05952413 ## Run 3 stress 0.04217396 ## ... Procrustes: rmse 4.597236e-05 max resid 0.0001189685 ## ... Similar to previous best ## Run 4 stress 0.04217403 ## ... Procrustes: rmse 0.0001487937 max resid 0.0004561402 ## ... Similar to previous best ## Run 5 stress 0.04217395 ## ... Procrustes: rmse 6.845306e-05 max resid 0.0002343482 ## ... Similar to previous best ## Run 6 stress 0.05952413 ## Run 7 stress 0.042174 ## ... Procrustes: rmse 0.0001351877 max resid 0.0004443447 ## ... Similar to previous best ## Run 8 stress 0.06761596 ## Run 9 stress 0.059524 ## Run 10 stress 0.04217407 ## ... Procrustes: rmse 0.0001709586 max resid 0.0005650254 ## ... Similar to previous best ## Run 11 stress 0.04217396 ## ... Procrustes: rmse 9.078681e-05 max resid 0.0003021391 ## ... Similar to previous best ## Run 12 stress 0.04217405 ## ... Procrustes: rmse 0.000168228 max resid 0.0005161761 ## ... Similar to previous best ## Run 13 stress 0.04217398 ## ... Procrustes: rmse 0.0001098377 max resid 0.0003567109 ## ... Similar to previous best ## Run 14 stress 0.042174 ## ... Procrustes: rmse 8.346652e-05 max resid 0.0002407597 ## ... Similar to previous best ## Run 15 stress 0.04217407 ## ... Procrustes: rmse 0.0001837054 max resid 0.0006272833 ## ... Similar to previous best ## Run 16 stress 0.04217406 ## ... Procrustes: rmse 0.0001481673 max resid 0.0003732481 ## ... Similar to previous best ## Run 17 stress 0.04217395 ## ... Procrustes: rmse 2.316957e-05 max resid 7.009862e-05 ## ... Similar to previous best ## Run 18 stress 0.04217396 ## ... Procrustes: rmse 8.182881e-05 max resid 0.0002803632 ## ... Similar to previous best ## Run 19 stress 0.04217397 ## ... Procrustes: rmse 0.0001031614 max resid 0.0003380335 ## ... Similar to previous best ## Run 20 stress 0.04217399 ## ... Procrustes: rmse 0.0001082464 max resid 0.0003554024 ## ... Similar to previous best ## *** Solution reached Then, we’ll take out the xyz values and plot them with plotly. wUFxyz = scores(wUF.nmds.3D, display = &quot;sites&quot;) wUFxyz ## NMDS1 NMDS2 NMDS3 ## 5017.1yr.F -0.19592858 0.107838852 0.07970378 ## 5017.2w.F 0.40344380 0.187070009 -0.11910580 ## 5017.8w.F -0.06745447 0.045811253 -0.21943422 ## 5020.1yr.F -0.21314445 0.100936809 0.06830615 ## 5020.2w.F -0.02919525 -0.163696093 -0.02924315 ## 5020.8w.F 0.03370365 0.054488455 -0.09105410 ## 5026.1yr.F -0.22486455 0.066643683 0.05598675 ## 5026.2w.F 0.13248515 -0.217106790 0.08751753 ## 5026.8w.F 0.39018092 0.135420606 0.24011653 ## 5031.1yr.F -0.19998566 0.080482377 0.09446961 ## 5031.2w.F 0.19092361 -0.256894303 0.01561278 ## 5031.8w.F -0.13588109 -0.042296559 -0.02585488 ## 5037.1yr.F -0.21803783 0.076509564 0.07189351 ## 5037.2w.F 0.05189732 -0.120255191 -0.04231306 ## 5037.8w.F 0.14232875 -0.115637316 -0.01896293 ## 5041.1yr.F -0.20914084 0.081785024 0.07442644 ## 5041.2w.F 0.27828678 -0.237773303 0.03642365 ## 5041.8w.F -0.13941945 -0.001654062 -0.18656492 ## 5045.1yr.F -0.23334457 0.051075686 0.06283287 ## 5045.2w.F 0.49235803 0.294995885 -0.14636092 ## 5045.8w.F -0.16920077 -0.126231476 -0.13821994 ## 5053.1yr.F -0.21544102 0.077998233 0.08008381 ## 5053.2w.F 0.27521892 -0.030406547 0.17560574 ## 5053.8w.F -0.13978837 -0.049104795 -0.12586523 plot_ly(x=wUFxyz[,1], y=wUFxyz[,2], z=wUFxyz[,3], type = &quot;scatter3d&quot;, mode = &quot;markers&quot;, color=meta$AgeGroup, colors=c(&quot;pink&quot;, &quot;purple&quot;, &quot;blue&quot;)) It is harder to visualize continuous variables in the way we’ve just visualized categorical values. We can, however, fit these as vectors on the nMDS plots. To do that, we’ll first fit the variables to our distances. We’ll use Bray-Curtis and weighted UniFrac for this, but you can do this with Jaccard aswell and you could also use unweighted UniFrac. fit.BC = envfit(BC.nmds, meta) fit.BC ## ## ***VECTORS ## ## NMDS1 NMDS2 r2 Pr(&gt;r) ## AgeExact -0.99893 -0.04630 0.9765 0.001 *** ## ADGKG 0.12541 0.99210 0.0771 0.444 ## chao -0.98550 0.16970 0.9598 0.001 *** ## shannon -0.69388 0.72009 0.9469 0.001 *** ## simpson 0.42089 -0.90711 0.7353 0.001 *** ## ace -0.99737 0.07248 0.9078 0.001 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## Permutation: free ## Number of permutations: 999 ## ## ***FACTORS: ## ## Centroids: ## NMDS1 NMDS2 ## Animalcow5017 -0.1827 0.5460 ## Animalcow5020 0.0065 0.6579 ## Animalcow5026 0.4231 -0.8839 ## Animalcow5031 -0.2440 0.1186 ## Animalcow5037 0.4943 -0.0574 ## Animalcow5041 0.0501 -0.0289 ## Animalcow5045 -0.1383 -0.3395 ## Animalcow5053 -0.4090 -0.0129 ## AgeGroup1yr -4.4483 -0.1795 ## AgeGroup2w 2.5035 -1.0530 ## AgeGroup8w 1.9447 1.2325 ## AgeGroup.ord2w 2.5035 -1.0530 ## AgeGroup.ord8w 1.9447 1.2325 ## AgeGroup.ord1yr -4.4483 -0.1795 ## ## Goodness of fit: ## r2 Pr(&gt;r) ## Animal 0.0248 0.997 ## AgeGroup 0.9133 0.001 *** ## AgeGroup.ord 0.9133 0.001 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## Permutation: free ## Number of permutations: 999 R has automatically fit every variable into the meta table. If we don’t want that, we can tell envfit to only run the variables we want. fit.BC = envfit(BC.nmds, meta[,c(&quot;AgeGroup&quot;, &quot;ADGKG&quot;)]) fit.BC ## ## ***VECTORS ## ## NMDS1 NMDS2 r2 Pr(&gt;r) ## ADGKG 0.12541 0.99210 0.0771 0.452 ## Permutation: free ## Number of permutations: 999 ## ## ***FACTORS: ## ## Centroids: ## NMDS1 NMDS2 ## AgeGroup1yr -4.4483 -0.1795 ## AgeGroup2w 2.5035 -1.0530 ## AgeGroup8w 1.9447 1.2325 ## ## Goodness of fit: ## r2 Pr(&gt;r) ## AgeGroup 0.9133 0.001 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## Permutation: free ## Number of permutations: 999 We’ll repeat this for the weighted UniFrac. fit.wUF = envfit(wUF.ordu, meta[,c(&quot;AgeGroup&quot;, &quot;ADGKG&quot;)]) fit.wUF ## ## ***VECTORS ## ## NMDS1 NMDS2 r2 Pr(&gt;r) ## ADGKG -0.17839 0.98396 0.0399 0.66 ## Permutation: free ## Number of permutations: 999 ## ## ***FACTORS: ## ## Centroids: ## NMDS1 NMDS2 ## AgeGroup1yr -0.1076 -0.0833 ## AgeGroup2w 0.1432 0.0322 ## AgeGroup8w -0.0356 0.0512 ## ## Goodness of fit: ## r2 Pr(&gt;r) ## AgeGroup 0.5588 0.001 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## Permutation: free ## Number of permutations: 999 We can plot the 2D nMDS with an arrow for the ADG, eventho the ADG isn’t a significant variable. Thus, you wouldn’t use this figure in a publication or such. We’ll do this with the Bray-Curtis dissimilarity. plot(BC.nmds, type = &quot;n&quot;, main = &quot;Bray-Curtis&quot;) points(BC.nmds, pch = 20, display = &quot;sites&quot;, col = c(&quot;pink&quot;, &quot;purple&quot;, &quot;blue&quot;))[meta$AgeGroup] ## NULL legend(-6, 2, legend = c(&quot;2w&quot;, &quot;8w&quot;, &quot;1yr&quot;), col = c(&quot;purple&quot;, &quot;blue&quot;, &quot;pink&quot;), pch = 20) plot(fit.BC, col = &quot;black&quot;) # Adding the fitted variables We can also only plot variables with p &lt; 0.05. That’d mean we’d only see the centroids. plot(BC.nmds, type = &quot;n&quot;, main = &quot;Bray-Curtis&quot;) points(BC.nmds, pch = 20, display = &quot;sites&quot;, col = c(&quot;blue&quot;, &quot;green&quot;, &quot;red&quot;))[meta$AgeGroup] ## NULL legend(-6, 2, legend = c(&quot;2w&quot;, &quot;8w&quot;, &quot;1yr&quot;), col = c(&quot;green&quot;, &quot;red&quot;, &quot;blue&quot;), pch = 20) plot(fit.BC, col = &quot;black&quot;, p.max = 0.05) We can also plot the weighted UniFrac. plot(wUF.ordu, type = &quot;n&quot;, main = &quot;Weighted UniFrac&quot;) points(wUF.ordu, pch = 20, display = &quot;sites&quot;, col = c(&quot;blue&quot;, &quot;green&quot;, &quot;red&quot;))[meta$AgeGroup] ## NULL legend(.3, .15, legend = c(&quot;2w&quot;, &quot;8w&quot;, &quot;1yr&quot;), col = c(&quot;green&quot;, &quot;red&quot;, &quot;blue&quot;), pch = 20) plot(fit.wUF, col = &quot;black&quot;) If we fit the OTU.clean data frame to the nMDS, we can add arrows for specific OTU’s in the plot. If an OTU arrow goes in the same direction as an age group centroid, that OTU tends to increase in abundance in that age group. Conversely, if an OTU arrow moves in the opposite direction of an age group centroid, that OTU probably decreases in abundance in that age group. We’ll only fit the first 10 OTU’s from our table, because it takes a long time. Then, we’ll only plot the significant arrows. fit.BC.OTU = envfit(BC.nmds, OTU.clean[,1:10]) fit.BC.OTU ## ## ***VECTORS ## ## NMDS1 NMDS2 r2 Pr(&gt;r) ## Otu00001 0.71703 -0.69704 0.2478 0.033 * ## Otu00002 0.46962 -0.88287 0.2108 0.057 . ## Otu00003 0.25731 -0.96633 0.2503 0.021 * ## Otu00004 0.25055 0.96810 0.2740 0.030 * ## Otu00005 0.15507 0.98790 0.2906 0.003 ** ## Otu00006 -0.96828 0.24987 0.6742 0.001 *** ## Otu00007 0.18000 -0.98367 0.2487 0.009 ** ## Otu00008 0.40221 0.91555 0.3108 0.016 * ## Otu00009 0.26281 -0.96485 0.1893 0.062 . ## Otu00010 0.33879 -0.94086 0.1552 0.078 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## Permutation: free ## Number of permutations: 999 plot(BC.nmds, type = &quot;n&quot;, main = &quot;Bray-Curtis&quot;) points(BC.nmds, pch = 20, display = &quot;sites&quot;, col = c(&quot;blue&quot;, &quot;green&quot;, &quot;red&quot;))[meta$AgeGroup] ## NULL legend(-6, -1.1, legend = c(&quot;2w&quot;, &quot;8w&quot;, &quot;1yr&quot;), col = c(&quot;green&quot;, &quot;red&quot;, &quot;blue&quot;), pch = 20) plot(fit.BC.OTU, col = &quot;black&quot;, p.max = 0.05) We can also plot summed genera or family groups of OTU’s. # Extracting all the OTU&#39;s within the Ruminococcus genus OTU.rumino = OTU.clean[,tax.clean$Genus == &quot;g__Ruminococcus&quot;] # Summing the abundances of the OTU&#39;s into one variable/column OTU.rumino$Rumino.sum = rowSums(OTU.rumino) # Fitting the Ruminococceae group fit.BC.rumino = envfit(BC.nmds, OTU.rumino$Rumino.sum) fit.BC.rumino ## ## ***VECTORS ## ## NMDS1 NMDS2 r2 Pr(&gt;r) ## [1,] -0.14496 0.98944 0.6622 0.001 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## Permutation: free ## Number of permutations: 999 # Plotting it plot(BC.nmds, type = &quot;n&quot;, main = &quot;Bray-Curtis&quot;) points(BC.nmds, pch = 20, display = &quot;sites&quot;, col = c(&quot;blue&quot;, &quot;green&quot;, &quot;red&quot;))[meta$AgeGroup] ## NULL legend(-6, -1.1, legend = c(&quot;2w&quot;, &quot;8w&quot;, &quot;1yr&quot;), col = c(&quot;green&quot;, &quot;red&quot;, &quot;blue&quot;), pch = 20) # Adding the fitted variables plot(fit.BC.rumino, col = &quot;black&quot;, labels = c(&quot;Ruminococcus&quot;)) "],["using-github-and-zotero.html", "7 Using GitHub and Zotero", " 7 Using GitHub and Zotero This was the sixth assignment for our portfolio. "],["making-a-website-on-github.html", "8 Making a website on GitHub", " 8 Making a website on GitHub This was the seventh assignment for our portfolio. We had to copy all our HTML’s to a new repository and make it into pretty website. "],["working-with-dbeaver-and-sql.html", "9 Working with DBeaver and SQL", " 9 Working with DBeaver and SQL library(tidyverse) library(readxl) library(dslabs) library(here) library(DBI) # install.packages(&quot;RPostgres&quot;) library(RPostgres) First, I read in the flu, dengue and gapminder data. flu &lt;- read_csv(here(&quot;data/data_raw/flu_data.csv&quot;), skip = 11) dengue &lt;- read_csv(here(&quot;data/data_raw/dengue_data.csv&quot;), skip = 11) gapminder &lt;- read_builtin(&quot;gapminder&quot;) The flu and dengue data wasn’t tidy yet, so I solved that by using the pivot_longer command to create the column “country” and “cases” in each of the datasets. That way, each country, date and number of cases had its own column. The gapminder dataset was already tidy. dengue_tidy &lt;- pivot_longer(data = dengue, cols = c(&quot;Argentina&quot;, &quot;Bolivia&quot;, &quot;Brazil&quot;, &quot;India&quot;, &quot;Indonesia&quot;, &quot;Mexico&quot;, &quot;Philippines&quot;, &quot;Singapore&quot;, &quot;Thailand&quot;, &quot;Venezuela&quot;), names_to = &quot;country_d&quot;, values_to = &quot;dengue_cases&quot;) flu_tidy &lt;- pivot_longer(data = flu, cols = c(&quot;Argentina&quot;, &quot;Australia&quot;, &quot;Austria&quot;, &quot;Belgium&quot;, &quot;Bolivia&quot;, &quot;Brazil&quot;, &quot;Bulgaria&quot;, &quot;Canada&quot;, &quot;Chile&quot;, &quot;France&quot;, &quot;Germany&quot;, &quot;Hungary&quot;, &quot;Japan&quot;, &quot;Mexico&quot;, &quot;Netherlands&quot;, &quot;New Zealand&quot;, &quot;Norway&quot;, &quot;Paraguay&quot;, &quot;Peru&quot;, &quot;Poland&quot;, &quot;Romania&quot;, &quot;Russia&quot;, &quot;South Africa&quot;, &quot;Spain&quot;, &quot;Sweden&quot;, &quot;Switzerland&quot;, &quot;Ukraine&quot;, &quot;United States&quot;, &quot;Uruguay&quot;), names_to = &quot;country_f&quot;, values_to = &quot;flu_cases&quot;) Next, I changed the flu and dengue data some more. I separated the Data column into the three columns “Year”, “Month” and “Day”. I also added a d or f after the column name “year”, so joining of the datasets in DBeaver will be possible later on. In the gapminder dataset, I changed the column “year” to “year_g” to also make joining more easy later on in DBeaver. flu_tidy &lt;- separate(flu_tidy, Date, into = c(&quot;year_f&quot;, &quot;month&quot;, &quot;day&quot;), sep = &quot;-&quot;) dengue_tidy&lt;- separate(dengue_tidy, Date, into = c(&quot;year_d&quot;, &quot;month&quot;, &quot;day&quot;), sep = &quot;-&quot;) flu_tidy$country_flu &lt;- as.factor(flu_tidy$country_f) flu_tidy$year &lt;- as.numeric(flu_tidy$year_f) dengue_tidy$country_dengue &lt;- as.factor(dengue_tidy$country_d) dengue_tidy$year &lt;- as.numeric(dengue_tidy$year_d) gapminder$country &lt;- as.factor(gapminder$country) dengue_tidy &lt;- as.data.frame(dengue_tidy) flu_tidy &lt;- as.data.frame(flu_tidy) dengue_tidy &lt;- dengue_tidy %&gt;% group_by(country_d, year_d) %&gt;% summarise_each(funs(sum), dengue_cases) flu_tidy &lt;- flu_tidy %&gt;% group_by(country_f, year_f) %&gt;% summarise_each(funs(sum), flu_cases) # Thanks to https://stackoverflow.com/questions/25089665/error-only-defined-on-a-data-frame-with-all-numeric-variables-with-ddply-on-lar for the summarise_each command :) gapminder &lt;- gapminder %&gt;% rename(year_g = &quot;year&quot;) Then I saved the three datasets as both .csv files and .rds files. write.csv(flu_tidy, &quot;Data//flu_data_tidy.csv&quot;, row.names = TRUE) write.csv(dengue_tidy, &quot;Data//dengue_data_tidy.csv&quot;, row.names = TRUE) write.csv(gapminder, &quot;Data//gapminder.csv&quot;, row.names = TRUE) saveRDS(flu_tidy, file = &quot;flu_data_tidy.rds&quot;) saveRDS(dengue_tidy, file = &quot;dengue_data_tidy.rds&quot;) saveRDS(gapminder, file = &quot;gapminder.rds&quot;) Next, I inserted the tables into the “workflowsdb” database in DBeaver. con &lt;- dbConnect(RPostgres::Postgres(), dbname = &quot;workflowsdb&quot;, host = &quot;localhost&quot;, port = &quot;5432&quot;, user = &quot;postgres&quot;, password = &quot;SQL22&quot;) dbWriteTable(con, &quot;flu_tidy&quot;, flu_tidy) dbWriteTable(con, &quot;dengue_tidy&quot;, dengue_tidy) dbWriteTable(con, &quot;gapminder&quot;, gapminder) dbDisconnect(con) Then I inspected the contents of the datasets in DBeaver and in R. # Inspecting the flu_tidy dataset flu_tidy %&gt;% arrange(desc(flu_cases)) ## # A tibble: 406 × 3 ## # Groups: country_f [29] ## country_f year_f flu_cases ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 South Africa 2014 155577 ## 2 South Africa 2009 150344 ## 3 Canada 2009 141118 ## 4 South Africa 2013 140671 ## 5 United States 2009 139394 ## 6 South Africa 2012 136519 ## 7 South Africa 2007 135522 ## 8 South Africa 2008 135377 ## 9 United States 2013 130196 ## 10 South Africa 2010 129539 ## # … with 396 more rows flu_tidy$flu_cases %&gt;% min(flu_tidy$flu_cases, na.rm = TRUE) ## [1] 106 flu_tidy$flu_cases %&gt;% max(flu_tidy$flu_cases, na.rm = TRUE) ## [1] 155577 # Inspecting the dengue_tidy dataset dengue_tidy %&gt;% arrange(desc(dengue_cases)) ## # A tibble: 140 × 3 ## # Groups: country_d [10] ## country_d year_d dengue_cases ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Venezuela 2010 27.8 ## 2 Venezuela 2014 22.8 ## 3 Thailand 2013 17.3 ## 4 Argentina 2009 16.7 ## 5 Venezuela 2009 15.8 ## 6 Venezuela 2013 15.7 ## 7 Venezuela 2008 15.6 ## 8 Venezuela 2007 15.3 ## 9 Indonesia 2007 15.0 ## 10 Philippines 2010 14.5 ## # … with 130 more rows dengue_tidy$dengue_cases %&gt;% min(dengue_tidy$dengue_cases, na.rm = TRUE) ## [1] 0.059 dengue_tidy$dengue_cases %&gt;% max(dengue_tidy$dengue_cases, na.rm = TRUE) ## [1] 27.847 # Inspecting the gapminder dataset gapminder$infant_mortality %&gt;% min(gapminder$infant_mortality, na.rm = TRUE) ## [1] 1.5 gapminder$infant_mortality %&gt;% max(gapminder$infant_mortality, na.rm = TRUE) ## [1] 276.9 gapminder$life_expectancy %&gt;% min(gapminder$life_expectancy, na.rm = TRUE) ## [1] 13.2 gapminder$life_expectancy %&gt;% max(gapminder$life_expectancy, na.rm = TRUE) ## [1] 83.9 gapminder %&gt;% select(country, year_g, life_expectancy) %&gt;% arrange(desc(life_expectancy)) ## country year_g life_expectancy ## 1 Hong Kong, China 2016 83.90 ## 2 Hong Kong, China 2015 83.73 ## 3 Hong Kong, China 2014 83.56 ## 4 Hong Kong, China 2013 83.38 ## 5 Iceland 2014 83.30 ## 6 Iceland 2015 83.30 ## 7 Iceland 2016 83.30 ## 8 Japan 2016 83.30 ## 9 Hong Kong, China 2012 83.20 ## 10 Iceland 2013 83.20 ## 11 Japan 2015 83.20 ## 12 Iceland 2012 83.10 ## 13 Japan 2014 83.10 ## 14 Switzerland 2016 83.10 ## 15 Hong Kong, China 2011 83.02 ## 16 Japan 2013 83.00 ## 17 Switzerland 2015 83.00 ## 18 Israel 2016 82.91 ## 19 Iceland 2011 82.90 ## 20 Japan 2012 82.90 ## 21 Switzerland 2014 82.90 ## 22 Hong Kong, China 2010 82.84 ## 23 Iceland 2010 82.80 ## 24 Switzerland 2013 82.80 ## 25 Japan 2009 82.70 ## 26 Japan 2010 82.70 ## 27 Switzerland 2012 82.70 ## 28 Spain 2016 82.70 ## 29 Hong Kong, China 2009 82.66 ## 30 Japan 2011 82.60 ## 31 Switzerland 2011 82.60 ## 32 Spain 2015 82.60 ## 33 Japan 2008 82.50 ## 34 Iceland 2009 82.50 ## 35 Spain 2013 82.50 ## 36 Spain 2014 82.50 ## 37 Hong Kong, China 2008 82.49 ## 38 Japan 2007 82.40 ## 39 Iceland 2008 82.40 ## 40 Australia 2012 82.40 ## 41 Australia 2013 82.40 ## 42 Hong Kong, China 2007 82.31 ## 43 Switzerland 2010 82.30 ## 44 Australia 2014 82.30 ## 45 Australia 2015 82.30 ## 46 Australia 2016 82.30 ## 47 Italy 2016 82.30 ## 48 Luxembourg 2016 82.30 ## 49 Japan 2006 82.20 ## 50 Australia 2011 82.20 ## 51 Spain 2012 82.20 ## 52 Italy 2015 82.20 ## 53 Luxembourg 2015 82.20 ## 54 Malta 2016 82.20 ## 55 Hong Kong, China 2006 82.12 ## 56 Iceland 2007 82.10 ## 57 Israel 2012 82.10 ## 58 Italy 2013 82.10 ## 59 Italy 2014 82.10 ## 60 Luxembourg 2014 82.10 ## 61 Sweden 2014 82.10 ## 62 Israel 2015 82.10 ## 63 Malta 2015 82.10 ## 64 Sweden 2015 82.10 ## 65 Singapore 2016 82.10 ## 66 Sweden 2016 82.10 ## 67 Japan 2005 82.00 ## 68 Switzerland 2008 82.00 ## 69 Switzerland 2009 82.00 ## 70 Australia 2010 82.00 ## 71 Italy 2011 82.00 ## 72 Spain 2011 82.00 ## 73 Italy 2012 82.00 ## 74 Israel 2013 82.00 ## 75 Malta 2014 82.00 ## 76 Norway 2014 82.00 ## 77 Norway 2015 82.00 ## 78 Singapore 2015 82.00 ## 79 Norway 2016 82.00 ## 80 Hong Kong, China 2005 81.92 ## 81 Japan 2004 81.90 ## 82 Italy 2010 81.90 ## 83 Luxembourg 2013 81.90 ## 84 Sweden 2013 81.90 ## 85 Singapore 2014 81.90 ## 86 Cyprus 2016 81.90 ## 87 France 2016 81.90 ## 88 Iceland 2006 81.80 ## 89 Australia 2009 81.80 ## 90 Spain 2010 81.80 ## 91 Sweden 2012 81.80 ## 92 Cyprus 2015 81.80 ## 93 France 2015 81.80 ## 94 Ireland 2016 81.80 ## 95 Japan 2003 81.70 ## 96 Iceland 2005 81.70 ## 97 Switzerland 2007 81.70 ## 98 Sweden 2011 81.70 ## 99 Luxembourg 2012 81.70 ## 100 Cyprus 2013 81.70 ## 101 France 2013 81.70 ## 102 Malta 2013 81.70 ## 103 Singapore 2013 81.70 ## 104 Canada 2014 81.70 ## 105 Cyprus 2014 81.70 ## 106 France 2014 81.70 ## 107 Canada 2015 81.70 ## 108 Ireland 2015 81.70 ## 109 Canada 2016 81.70 ## 110 Hong Kong, China 2004 81.68 ## 111 Japan 2002 81.60 ## 112 Australia 2008 81.60 ## 113 Italy 2009 81.60 ## 114 Israel 2010 81.60 ## 115 Sweden 2010 81.60 ## 116 Canada 2011 81.60 ## 117 France 2011 81.60 ## 118 Israel 2011 81.60 ## 119 Canada 2012 81.60 ## 120 France 2012 81.60 ## 121 Malta 2012 81.60 ## 122 Norway 2012 81.60 ## 123 Singapore 2012 81.60 ## 124 Canada 2013 81.60 ## 125 Norway 2013 81.60 ## 126 Ireland 2014 81.60 ## 127 Iceland 2004 81.50 ## 128 Switzerland 2006 81.50 ## 129 Australia 2007 81.50 ## 130 Italy 2008 81.50 ## 131 Spain 2009 81.50 ## 132 Luxembourg 2011 81.50 ## 133 Singapore 2011 81.50 ## 134 Cyprus 2012 81.50 ## 135 Ireland 2013 81.50 ## 136 Hong Kong, China 2003 81.40 ## 137 Australia 2006 81.40 ## 138 France 2010 81.40 ## 139 New Zealand 2013 81.40 ## 140 New Zealand 2014 81.40 ## 141 New Zealand 2015 81.40 ## 142 Austria 2016 81.40 ## 143 New Zealand 2016 81.40 ## 144 Japan 2001 81.30 ## 145 Iceland 2003 81.30 ## 146 Switzerland 2005 81.30 ## 147 Italy 2007 81.30 ## 148 Canada 2010 81.30 ## 149 Luxembourg 2010 81.30 ## 150 Malta 2010 81.30 ## 151 Singapore 2010 81.30 ## 152 Malta 2011 81.30 ## 153 Israel 2014 81.30 ## 154 Netherlands 2014 81.30 ## 155 Austria 2015 81.30 ## 156 Netherlands 2015 81.30 ## 157 Netherlands 2016 81.30 ## 158 Australia 2005 81.20 ## 159 Italy 2006 81.20 ## 160 France 2009 81.20 ## 161 Luxembourg 2009 81.20 ## 162 Malta 2009 81.20 ## 163 Sweden 2009 81.20 ## 164 Netherlands 2013 81.20 ## 165 Austria 2014 81.20 ## 166 Italy 2005 81.10 ## 167 France 2008 81.10 ## 168 Spain 2008 81.10 ## 169 Sweden 2008 81.10 ## 170 Canada 2009 81.10 ## 171 Norway 2010 81.10 ## 172 Cyprus 2011 81.10 ## 173 Norway 2011 81.10 ## 174 Ireland 2012 81.10 ## 175 New Zealand 2012 81.10 ## 176 Austria 2013 81.10 ## 177 South Korea 2016 81.10 ## 178 United Kingdom 2016 81.10 ## 179 Hong Kong, China 2002 81.08 ## 180 Macao, China 2016 81.03 ## 181 Japan 2000 81.00 ## 182 Iceland 2002 81.00 ## 183 Switzerland 2004 81.00 ## 184 Malta 2006 81.00 ## 185 France 2007 81.00 ## 186 Luxembourg 2008 81.00 ## 187 Israel 2009 81.00 ## 188 Singapore 2009 81.00 ## 189 Ireland 2010 81.00 ## 190 Netherlands 2012 81.00 ## 191 Greece 2013 81.00 ## 192 Greece 2014 81.00 ## 193 Greece 2015 81.00 ## 194 South Korea 2015 81.00 ## 195 United Kingdom 2015 81.00 ## 196 Greece 2016 81.00 ## 197 Slovenia 2016 81.00 ## 198 Australia 2004 80.90 ## 199 Italy 2004 80.90 ## 200 Malta 2007 80.90 ## 201 Sweden 2007 80.90 ## 202 Netherlands 2011 80.90 ## 203 Austria 2012 80.90 ## 204 South Korea 2013 80.90 ## 205 Finland 2014 80.90 ## 206 South Korea 2014 80.90 ## 207 United Kingdom 2014 80.90 ## 208 Finland 2015 80.90 ## 209 Slovenia 2015 80.90 ## 210 Finland 2016 80.90 ## 211 Germany 2016 80.90 ## 212 Portugal 2016 80.90 ## 213 Macao, China 2015 80.82 ## 214 Iceland 2001 80.80 ## 215 Sweden 2006 80.80 ## 216 Spain 2007 80.80 ## 217 Canada 2008 80.80 ## 218 Norway 2008 80.80 ## 219 Norway 2009 80.80 ## 220 Netherlands 2010 80.80 ## 221 New Zealand 2010 80.80 ## 222 New Zealand 2011 80.80 ## 223 Finland 2013 80.80 ## 224 United Kingdom 2013 80.80 ## 225 Slovenia 2014 80.80 ## 226 Germany 2015 80.80 ## 227 Portugal 2015 80.80 ## 228 Hong Kong, China 2001 80.73 ## 229 Malta 2005 80.70 ## 230 France 2006 80.70 ## 231 Spain 2006 80.70 ## 232 Malta 2008 80.70 ## 233 Austria 2011 80.70 ## 234 South Korea 2012 80.70 ## 235 United Kingdom 2012 80.70 ## 236 Germany 2013 80.70 ## 237 Portugal 2013 80.70 ## 238 Germany 2014 80.70 ## 239 Portugal 2014 80.70 ## 240 Macao, China 2014 80.61 ## 241 Japan 1999 80.60 ## 242 Australia 2003 80.60 ## 243 Switzerland 2003 80.60 ## 244 Sweden 2005 80.60 ## 245 Canada 2007 80.60 ## 246 Luxembourg 2007 80.60 ## 247 Norway 2007 80.60 ## 248 Israel 2008 80.60 ## 249 Singapore 2008 80.60 ## 250 Netherlands 2009 80.60 ## 251 Cyprus 2010 80.60 ## 252 Ireland 2011 80.60 ## 253 South Korea 2011 80.60 ## 254 Germany 2012 80.60 ## 255 Greece 2012 80.60 ## 256 Japan 1998 80.50 ## 257 Iceland 2000 80.50 ## 258 Canada 2006 80.50 ## 259 New Zealand 2009 80.50 ## 260 Austria 2010 80.50 ## 261 Germany 2011 80.50 ## 262 Greece 2011 80.50 ## 263 United Kingdom 2011 80.50 ## 264 Finland 2012 80.50 ## 265 Belgium 2014 80.50 ## 266 Belgium 2015 80.50 ## 267 Belgium 2016 80.50 ## 268 Denmark 2016 80.50 ## 269 Japan 1997 80.40 ## 270 Switzerland 2002 80.40 ## 271 France 2005 80.40 ## 272 Norway 2006 80.40 ## 273 Singapore 2007 80.40 ## 274 Austria 2008 80.40 ## 275 Greece 2010 80.40 ## 276 South Korea 2010 80.40 ## 277 Portugal 2012 80.40 ## 278 Belgium 2013 80.40 ## 279 Macao, China 2013 80.40 ## 280 Denmark 2015 80.40 ## 281 Costa Rica 2016 80.40 ## 282 Kuwait 2016 80.40 ## 283 Hong Kong, China 2000 80.36 ## 284 Australia 2002 80.30 ## 285 Malta 2004 80.30 ## 286 Spain 2005 80.30 ## 287 Luxembourg 2006 80.30 ## 288 Israel 2007 80.30 ## 289 Netherlands 2008 80.30 ## 290 New Zealand 2008 80.30 ## 291 Austria 2009 80.30 ## 292 Cyprus 2009 80.30 ## 293 Ireland 2009 80.30 ## 294 Germany 2010 80.30 ## 295 Finland 2011 80.30 ## 296 Belgium 2012 80.30 ## 297 Denmark 2012 80.30 ## 298 Denmark 2013 80.30 ## 299 Slovenia 2013 80.30 ## 300 Denmark 2014 80.30 ## 301 Costa Rica 2015 80.30 ## 302 Kuwait 2015 80.30 ## 303 Japan 1996 80.20 ## 304 Iceland 1999 80.20 ## 305 Switzerland 2001 80.20 ## 306 Sweden 2003 80.20 ## 307 France 2004 80.20 ## 308 Sweden 2004 80.20 ## 309 Canada 2005 80.20 ## 310 Norway 2005 80.20 ## 311 Singapore 2006 80.20 ## 312 Netherlands 2007 80.20 ## 313 Greece 2008 80.20 ## 314 Greece 2009 80.20 ## 315 United Kingdom 2010 80.20 ## 316 Belgium 2011 80.20 ## 317 Portugal 2011 80.20 ## 318 Costa Rica 2014 80.20 ## 319 Kuwait 2014 80.20 ## 320 Macao, China 2012 80.19 ## 321 Australia 2001 80.10 ## 322 Italy 2002 80.10 ## 323 Italy 2003 80.10 ## 324 Malta 2003 80.10 ## 325 Canada 2004 80.10 ## 326 Austria 2007 80.10 ## 327 Ireland 2007 80.10 ## 328 New Zealand 2007 80.10 ## 329 Ireland 2008 80.10 ## 330 Germany 2009 80.10 ## 331 South Korea 2009 80.10 ## 332 Belgium 2010 80.10 ## 333 Slovenia 2012 80.10 ## [ reached &#39;max&#39; / getOption(&quot;max.print&quot;) -- omitted 10212 rows ] gapminder %&gt;% select( country, year_g, infant_mortality) %&gt;% arrange(desc(infant_mortality)) ## country year_g infant_mortality ## 1 Yemen 1963 276.90 ## 2 Yemen 1964 270.70 ## 3 Yemen 1961 269.20 ## 4 Yemen 1962 263.70 ## 5 Yemen 1965 263.60 ## 6 Yemen 1966 256.00 ## 7 Yemen 1967 247.80 ## 8 Yemen 1968 239.20 ## 9 Mali 1960 237.40 ## 10 Oman 1961 237.20 ## 11 Mali 1961 231.50 ## 12 Yemen 1969 230.00 ## 13 Oman 1962 226.00 ## 14 Mali 1962 225.20 ## 15 Yemen 1960 225.00 ## 16 Sierra Leone 1960 223.60 ## 17 Yemen 1970 221.10 ## 18 Sierra Leone 1961 220.50 ## 19 Nepal 1960 219.60 ## 20 Oman 1963 218.70 ## 21 Malawi 1960 218.20 ## 22 Sierra Leone 1962 217.50 ## 23 Maldives 1963 217.10 ## 24 Nepal 1961 216.70 ## 25 Mali 1963 216.50 ## 26 Malawi 1961 216.40 ## 27 Malawi 1962 214.60 ## 28 Malawi 1964 214.30 ## 29 Sierra Leone 1963 214.20 ## 30 Nepal 1962 213.30 ## 31 Malawi 1965 213.30 ## 32 Malawi 1963 212.90 ## 33 Mali 1964 212.80 ## 34 Yemen 1971 212.50 ## 35 Malawi 1966 212.30 ## 36 Liberia 1961 212.10 ## 37 Liberia 1960 212.00 ## 38 Malawi 1967 211.50 ## 39 Liberia 1962 211.40 ## 40 Maldives 1964 211.10 ## 41 Sierra Leone 1964 211.00 ## 42 Malawi 1968 210.80 ## 43 Guinea 1961 210.50 ## 44 Liberia 1963 210.40 ## 45 Egypt 1960 209.60 ## 46 Malawi 1969 209.60 ## 47 Nepal 1963 209.40 ## 48 Mali 1965 209.20 ## 49 Guinea 1962 209.10 ## 50 Liberia 1964 208.80 ## 51 Cote d&#39;Ivoire 1960 208.40 ## 52 Angola 1960 208.00 ## 53 Oman 1964 207.90 ## 54 Malawi 1970 207.70 ## 55 Guinea 1963 207.60 ## 56 Sierra Leone 1965 207.60 ## 57 Liberia 1965 206.80 ## 58 Guinea 1964 206.10 ## 59 Mali 1966 206.10 ## 60 Maldives 1965 205.30 ## 61 Nepal 1964 205.20 ## 62 Malawi 1971 204.80 ## 63 Liberia 1966 204.60 ## 64 Guinea 1965 204.50 ## 65 Yemen 1972 204.30 ## 66 Sierra Leone 1966 204.20 ## 67 Cote d&#39;Ivoire 1961 203.00 ## 68 Mali 1967 203.00 ## 69 Egypt 1961 202.70 ## 70 Guinea 1966 202.60 ## 71 Liberia 1967 201.70 ## 72 Guinea 1967 200.90 ## 73 Sierra Leone 1967 200.80 ## 74 Nepal 1965 200.70 ## 75 Malawi 1972 200.60 ## 76 Mali 1968 200.30 ## 77 Comoros 1960 200.00 ## 78 Maldives 1966 199.20 ## 79 Guinea 1968 199.00 ## 80 Liberia 1968 198.50 ## 81 Mali 1969 197.90 ## 82 Cote d&#39;Ivoire 1962 197.70 ## 83 Oman 1965 197.60 ## 84 Sierra Leone 1968 197.30 ## 85 Guinea 1969 197.10 ## 86 Yemen 1973 196.70 ## 87 Egypt 1962 195.90 ## 88 Nepal 1966 195.90 ## 89 Mali 1970 195.70 ## 90 Malawi 1973 195.50 ## 91 Nigeria 1964 195.40 ## 92 Guinea 1970 195.20 ## 93 Liberia 1969 194.90 ## 94 Haiti 1960 194.80 ## 95 Sierra Leone 1969 194.10 ## 96 Mali 1971 193.50 ## 97 Guinea 1971 193.20 ## 98 Maldives 1967 193.10 ## 99 Cote d&#39;Ivoire 1963 192.80 ## 100 Bhutan 1968 192.10 ## 101 Pakistan 1960 192.00 ## 102 Iran 1960 191.61 ## 103 Haiti 1961 191.50 ## 104 Iran 1967 191.30 ## 105 Nepal 1967 191.30 ## 106 Liberia 1970 191.30 ## 107 Guinea 1972 191.10 ## 108 Mali 1972 191.10 ## 109 Nigeria 1965 191.00 ## 110 Sierra Leone 1970 191.00 ## 111 China 1960 190.00 ## 112 Malawi 1974 189.90 ## 113 Egypt 1963 189.40 ## 114 Guinea 1973 189.10 ## 115 Yemen 1974 189.00 ## 116 Haiti 1962 188.30 ## 117 Mali 1973 188.20 ## 118 Cote d&#39;Ivoire 1964 188.00 ## 119 Sierra Leone 1971 188.00 ## 120 Oman 1966 187.80 ## 121 Liberia 1971 187.80 ## 122 Tunisia 1961 187.50 ## 123 Benin 1960 186.90 ## 124 Maldives 1968 186.90 ## 125 Nigeria 1966 186.80 ## 126 Nepal 1968 186.80 ## 127 Guinea 1974 186.80 ## 128 Bhutan 1969 186.00 ## 129 Mozambique 1965 185.60 ## 130 Haiti 1963 185.20 ## 131 Sierra Leone 1972 185.20 ## 132 Mozambique 1966 185.00 ## 133 Pakistan 1961 184.80 ## 134 Mali 1974 184.80 ## 135 Guinea 1975 184.50 ## 136 Liberia 1972 184.40 ## 137 Mozambique 1967 184.10 ## 138 Malawi 1975 184.00 ## 139 Benin 1961 183.90 ## 140 Iran 1961 183.85 ## 141 Mozambique 1968 183.50 ## 142 Egypt 1964 183.40 ## 143 Cote d&#39;Ivoire 1965 183.30 ## 144 Mozambique 1960 183.00 ## 145 Nigeria 1962 182.60 ## 146 Nigeria 1967 182.60 ## 147 Mozambique 1969 182.60 ## 148 Nepal 1969 182.60 ## 149 Sierra Leone 1973 182.60 ## 150 Haiti 1964 182.20 ## 151 Mozambique 1970 181.90 ## 152 Guinea 1976 181.90 ## 153 Nigeria 1963 181.40 ## 154 Bhutan 1970 181.20 ## 155 Mozambique 1971 181.20 ## 156 Yemen 1975 181.20 ## 157 Liberia 1973 181.00 ## 158 Mali 1975 180.90 ## 159 Benin 1962 180.60 ## 160 Mozambique 1964 180.50 ## 161 Maldives 1969 180.50 ## 162 Mozambique 1972 180.50 ## 163 Angola 1970 180.00 ## 164 Sierra Leone 1974 180.00 ## 165 Mozambique 1973 179.80 ## 166 Haiti 1965 179.10 ## 167 Guinea 1977 179.10 ## 168 Mozambique 1974 179.00 ## 169 Tunisia 1962 178.70 ## 170 Cote d&#39;Ivoire 1966 178.70 ## 171 Nepal 1970 178.60 ## 172 Oman 1967 178.50 ## 173 Nigeria 1968 178.20 ## 174 Cambodia 1975 178.20 ## 175 Egypt 1965 178.10 ## 176 Pakistan 1962 178.00 ## 177 Mozambique 1975 178.00 ## 178 Liberia 1974 177.50 ## 179 Sierra Leone 1975 177.50 ## 180 Malawi 1976 177.50 ## 181 Mozambique 1976 177.20 ## 182 Benin 1963 177.10 ## 183 Mali 1976 176.90 ## 184 Iran 1968 176.80 ## 185 Mozambique 1977 176.40 ## 186 Iran 1962 176.37 ## 187 Bangladesh 1960 176.30 ## 188 Bhutan 1971 176.20 ## 189 Guinea 1978 176.20 ## 190 Haiti 1966 176.00 ## 191 Mozambique 1978 175.70 ## 192 Sierra Leone 1976 175.30 ## 193 Mozambique 1979 175.10 ## 194 Bhutan 1960 175.00 ## 195 Nepal 1971 174.60 ## 196 Mozambique 1980 174.60 ## 197 Cote d&#39;Ivoire 1967 174.20 ## 198 Liberia 1975 174.20 ## 199 Mozambique 1981 174.10 ## 200 Congo, Dem. Rep. 1960 174.00 ## 201 Maldives 1970 174.00 ## 202 Nigeria 1969 173.70 ## 203 Benin 1964 173.60 ## 204 Egypt 1966 173.60 ## 205 Bolivia 1960 173.40 ## 206 Tunisia 1960 173.40 ## 207 Mozambique 1982 173.30 ## 208 Sierra Leone 1977 173.20 ## 209 Guinea 1979 173.20 ## 210 Yemen 1976 173.10 ## 211 Haiti 1967 172.90 ## 212 Mali 1977 172.80 ## 213 Mozambique 1983 172.30 ## 214 Bangladesh 1961 171.70 ## 215 Pakistan 1963 171.70 ## 216 Liberia 1976 171.30 ## 217 Bhutan 1972 171.20 ## 218 Sierra Leone 1978 171.20 ## 219 Liberia 1991 171.20 ## 220 Tunisia 1963 170.90 ## 221 Nepal 1972 170.90 ## 222 Mozambique 1984 170.90 ## 223 Malawi 1977 170.60 ## 224 Bolivia 1961 170.50 ## 225 Liberia 1992 170.30 ## 226 Benin 1965 170.20 ## 227 Guinea 1980 170.20 ## 228 Timor-Leste 1983 170.20 ## 229 Liberia 1990 170.10 ## 230 Egypt 1967 169.90 ## 231 Cote d&#39;Ivoire 1968 169.90 ## 232 Haiti 1968 169.80 ## 233 Oman 1968 169.30 ## 234 Iran 1963 169.26 ## 235 Sierra Leone 1979 169.20 ## 236 Mozambique 1985 169.20 ## 237 Nigeria 1970 168.90 ## 238 Mali 1978 168.70 ## 239 Liberia 1977 168.30 ## 240 Liberia 1993 167.80 ## 241 Bolivia 1962 167.70 ## 242 Liberia 1989 167.70 ## 243 Bangladesh 1962 167.60 ## 244 Mozambique 1986 167.50 ## 245 Sierra Leone 1980 167.30 ## 246 Guinea 1981 167.30 ## 247 Nepal 1973 167.20 ## 248 Maldives 1971 167.10 ## 249 Cameroon 1960 166.90 ## 250 Egypt 1968 166.90 ## 251 Benin 1966 166.80 ## 252 Haiti 1969 166.60 ## 253 Bhutan 1973 166.40 ## 254 Cambodia 1976 166.40 ## 255 Turkey 1960 166.00 ## 256 Pakistan 1964 165.80 ## 257 Liberia 1978 165.70 ## 258 Mozambique 1987 165.70 ## 259 Sierra Leone 1981 165.60 ## 260 Central African Republic 1960 165.50 ## 261 Cote d&#39;Ivoire 1969 165.40 ## 262 India 1960 165.10 ## 263 Nigeria 1960 165.00 ## 264 Bolivia 1963 165.00 ## 265 Mali 1979 164.80 ## 266 Yemen 1977 164.60 ## 267 Liberia 1988 164.60 ## 268 Libya 1960 164.50 ## 269 Egypt 1969 164.30 ## 270 Guinea 1982 164.30 ## 271 Nigeria 1971 164.10 ## 272 Sierra Leone 1982 164.10 ## 273 Oman 1960 164.00 ## 274 Benin 1967 164.00 ## 275 Malawi 1978 163.80 ## 276 Mozambique 1988 163.80 ## 277 Bangladesh 1963 163.70 ## 278 Liberia 1994 163.70 ## 279 Nepal 1974 163.60 ## 280 Timor-Leste 1984 163.50 ## 281 Haiti 1970 163.40 ## 282 Cameroon 1961 163.30 ## 283 Tunisia 1964 163.20 ## 284 Iran 1969 163.10 ## 285 Liberia 1979 163.10 ## 286 Central African Republic 1961 162.90 ## 287 Sierra Leone 1983 162.80 ## 288 India 1961 162.50 ## 289 Iran 1964 162.50 ## 290 Togo 1960 162.40 ## 291 Bolivia 1964 162.20 ## 292 Ethiopia 1960 162.00 ## 293 Egypt 1970 162.00 ## 294 Mozambique 1989 161.80 ## 295 Turkey 1961 161.60 ## 296 Bhutan 1974 161.60 ## 297 Benin 1968 161.50 ## 298 Sierra Leone 1984 161.50 ## 299 Liberia 1987 161.50 ## 300 Guinea 1983 161.40 ## 301 Burkina Faso 1960 161.30 ## 302 Mali 1980 161.20 ## 303 China 1961 161.00 ## 304 Cote d&#39;Ivoire 1970 161.00 ## 305 Liberia 1980 160.80 ## 306 Cameroon 1962 160.50 ## 307 Pakistan 1965 160.50 ## 308 Central African Republic 1962 160.40 ## 309 Oman 1969 160.40 ## 310 Sierra Leone 1985 160.40 ## 311 Bangladesh 1964 160.30 ## 312 India 1962 160.10 ## 313 Haiti 1971 160.10 ## 314 Nepal 1975 159.90 ## 315 Maldives 1972 159.70 ## 316 Mozambique 1990 159.70 ## 317 Egypt 1971 159.60 ## 318 Burkina Faso 1961 159.40 ## 319 Togo 1961 159.40 ## 320 Bolivia 1965 159.40 ## 321 Sierra Leone 1986 159.40 ## 322 Benin 1969 159.20 ## 323 Nigeria 1972 159.20 ## 324 Liberia 1981 158.70 ## 325 Liberia 1986 158.60 ## 326 Guinea 1984 158.50 ## 327 Sierra Leone 1987 158.30 ## 328 Liberia 1995 158.30 ## 329 Cameroon 1963 158.10 ## 330 Mali 1981 157.70 ## 331 Central African Republic 1963 157.60 ## 332 India 1963 157.60 ## 333 Sierra Leone 1988 157.60 ## [ reached &#39;max&#39; / getOption(&quot;max.print&quot;) -- omitted 10212 rows ] "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
